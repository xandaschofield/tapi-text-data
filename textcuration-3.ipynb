{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Xanda Schofield](https://www.cs.hmc.edu/~xanda) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/).\n",
    "\n",
    "For questions/comments/improvements, email xanda@cs.hmc.edu.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Curation 3\n",
    "\n",
    "This is lesson 3 of 3 in the educational series on Text Data Curation. This notebook is intended to look at how trained models, such as naive Bayes models and topic models, can actually help the text curation process. \n",
    "\n",
    "**Audience:** `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** [`How-To`](https://constellate.org/docs/documentation-categories#howtoproblemoriented) \n",
    "\n",
    "**Difficulty:** `Intermediate`\n",
    "Assumes users are familiar with Python and have been programming for 6+ months. Code makes up a larger part of the notebook and basic concepts related to Python are not explained.\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "* Python basics (variables, flow control, functions, lists, dictionaries)\n",
    "* How Python libraries work (installation and imports)\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "* Basic file operations (open, close, read, write)\n",
    "* How text is stored on computers\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "1. Use a lexicon to retrieve interesting documents\n",
    "2. Augment a lexicon using correlation between words\n",
    "3. Use a simple topic model to check for oddities in a corpus\n",
    "\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    "\n",
    "* `nltk`\n",
    "* `numpy`\n",
    "* `sklearn`\n",
    "\n",
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in /home/xanda/anaconda3/lib/python3.8/site-packages (0.23.2)\r\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/xanda/anaconda3/lib/python3.8/site-packages (from scikit-learn) (2.1.0)\r\n",
      "Requirement already satisfied: scipy>=0.19.1 in /home/xanda/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.5.2)\r\n",
      "Requirement already satisfied: numpy>=1.13.3 in /home/xanda/anaconda3/lib/python3.8/site-packages (from scikit-learn) (1.19.2)\r\n",
      "Requirement already satisfied: joblib>=0.11 in /home/xanda/anaconda3/lib/python3.8/site-packages (from scikit-learn) (0.17.0)\r\n"
     ]
    }
   ],
   "source": [
    "### Install Libraries ###\n",
    "\n",
    "# # Using !pip installs\n",
    "!pip install scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Import Libraries ###\n",
    "from collections import Counter\n",
    "import csv\n",
    "import os\n",
    "import urllib.request\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np\n",
    "from scipy.stats import spearmanr\n",
    "\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import mutual_info_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Data\n",
    "\n",
    "**Data Format:** \n",
    "* comma-separated value (.csv)\n",
    "\n",
    "**Data Source:**\n",
    "* [Rotten Tomatoes Dataset](https://www.kaggle.com/datasets/stefanoleone992/rotten-tomatoes-movies-and-critic-reviews-dataset)\n",
    "\n",
    "\n",
    "## Download Required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve multiple files using a list ###\n",
    "\n",
    "download_urls = [\n",
    "    'https://cs.hmc.edu/~xanda/data/rotten_tomatoes_critic_reviews_50k.csv',\n",
    "    # https://cs.hmc.edu/~xanda/data/rotten_tomatoes_critic_reviews_50k.csv', # the full dataset\n",
    "    'https://cs.hmc.edu/~xanda/data/rotten_tomatoes_movies.csv',\n",
    "    'https://cs.hmc.edu/~xanda/data/stoplist_en.txt' # a modification of an English stoplist constructed by David Mimno\n",
    "]\n",
    "\n",
    "for url in download_urls:\n",
    "    urllib.request.urlretrieve(url, url.rsplit('/', 1)[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "In the last section, we looked at classic ways to get data prepared to use for analysis. Today, we will do two types of analysis: first, finding terms within a lexicon, and second, running a topic model. However, our goal right now is not going to be finishing analysis, but instead starting to try things out and spot if there are subtler issues with our corpus."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our third and last lesson, our dataset will be a collection of RottenTomatoes reviews posted on Kaggle. (I sampled 50k reviews so it wouldn't take forever to download and run, but if you'd like the full collection you can comment out the lines above and below to download and load in the whole thing.)\n",
    "\n",
    "## Inspecting and slicing data\n",
    "\n",
    "Before we get far, let's go ahead and inspect our data by loading it in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# big file alternative:\n",
    "# with open(\"rotten_tomatoes_critic_reviews.csv\", encoding='utf-8') as reviews_file:\n",
    "with open(\"rotten_tomatoes_critic_reviews_50k.csv\", encoding='utf-8') as reviews_file:\n",
    "    csvr = csv.DictReader(reviews_file)\n",
    "    review_data = [row for row in csvr]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's confirm we do have 50,000 reviews in our reviews file and what data we get with each:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of reviews: 50000\n",
      "{'rotten_tomatoes_link': 'm/the_king_of_staten_island', 'critic_name': 'Roger Tennis', 'top_critic': 'False', 'publisher_name': 'Cinemaclips.com', 'review_type': 'Fresh', 'review_score': '3.5/5', 'review_date': '2020-06-11', 'review_content': \"SNL's Pete Davidson is a commanding presence in this appealing comedy/drama.\"}\n"
     ]
    }
   ],
   "source": [
    "print(\"# of reviews:\", len(review_data))\n",
    "print(review_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting - we get the review and reviewer information, but instead of getting a proper movie title or metadata about the movie, we just get a `rotten_tomatoes_link` to the part of the URL where a movie is. That's because there's a second CSV with metadata for each movie. Since we're going to be doing some cross-referencing between multiple dictionaries of things and it'll be easy to mistype, I'm going to leave myself some variables with the keys I need to pull information I care about: a unique ID for each movie, and where the text of the review is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ID_LINK = 'rotten_tomatoes_link'\n",
    "TEXT = 'review_content'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at what's in the second CSV of movie data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"rotten_tomatoes_movies.csv\", encoding='utf-8') as movies_file:\n",
    "    csvr = csv.DictReader(movies_file)\n",
    "    movie_data = [row for row in csvr]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of movies: 17712\n",
      "{'rotten_tomatoes_link': 'm/0814255', 'movie_title': 'Percy Jackson & the Olympians: The Lightning Thief', 'movie_info': \"Always trouble-prone, the life of teenager Percy Jackson (Logan Lerman) gets a lot more complicated when he learns he's the son of the Greek god Poseidon. At a training ground for the children of deities, Percy learns to harness his divine powers and prepare for the adventure of a lifetime: he must prevent a feud among the Olympians from erupting into a devastating war on Earth, and rescue his mother from the clutches of Hades, god of the underworld.\", 'critics_consensus': 'Though it may seem like just another Harry Potter knockoff, Percy Jackson benefits from a strong supporting cast, a speedy plot, and plenty of fun with Greek mythology.', 'content_rating': 'PG', 'genres': 'Action & Adventure, Comedy, Drama, Science Fiction & Fantasy', 'directors': 'Chris Columbus', 'authors': 'Craig Titley, Chris Columbus, Rick Riordan', 'actors': \"Logan Lerman, Brandon T. Jackson, Alexandra Daddario, Jake Abel, Sean Bean, Pierce Brosnan, Steve Coogan, Rosario Dawson, Melina Kanakaredes, Catherine Keener, Kevin Mckidd, Joe Pantoliano, Uma Thurman, Ray Winstone, Julian Richings, Bonita Friedericy, Annie Ilonzeh, Tania Saulnier, Marie Avgeropoulos, Luisa D'Oliveira, Christie Laing, Marielle Jaffe, Elisa King, Chrystal Tisiga, Alexis Knapp, Charlie Gallant, Chelan Simmons, Andrea Brooks, Natassia Malthe, Max Van Ville, Serinda Swan, Dimitri Lekkos, Ona Grauer, Stefanie von Pfetten, Conrad Coates, Erica Cerra, Dylan Neal, Luke Camilleri, Holly Hougham, Ina Geraldine, Raquel Riskin, Yusleidis Oquendo, Janine Edwards, Valerie Tian, Violet Columbus, Sarah Smyth, Merritt Patterson, Julie Luck, Andrea Day, John Stewart, Suzanne Ristic, Deejay Jackson, Matthew Garrick, Stan Carp, Suzanna Ristic, Richard Harmon, Maria Olsen, Robin Lemon, Doyle Devereux, Tom Pickett, VJ Delos-Reyes, Tim Aas, Keith Dallas, Spencer Atkinson, Maya Washington, Loyd Bateman, Victor Ayala, Zane Holtz, Eli Zagoudakis, Matt Reimer, Rob Hayter, Lloyd Bateman, Shawn Beaton, Jarod Joseph, Reilly Dolman, Paul Cummings, Julie Brar, Dejan Loyola, Damian Arman, Mario Casoria, Dorla Bell, Carolyn Adair (II), Jade Pawluk, G. Patrick Currie, Darian Arman, Mariela Zapata, David L. Smith\", 'original_release_date': '2010-02-12', 'streaming_release_date': '2015-11-25', 'runtime': '119', 'production_company': '20th Century Fox', 'tomatometer_status': 'Rotten', 'tomatometer_rating': '49', 'tomatometer_count': '149', 'audience_status': 'Spilled', 'audience_rating': '53', 'audience_count': '254421', 'tomatometer_top_critics_count': '43', 'tomatometer_fresh_critics_count': '73', 'tomatometer_rotten_critics_count': '76'}\n"
     ]
    }
   ],
   "source": [
    "print(\"# of movies:\", len(movie_data))\n",
    "print(movie_data[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we go: this gives us movie information and, lucky for us, also has a `rotten_tomatoes_link` we can use to cross-reference between the two CSVs. We're going to quickly make a dictionary to help us look up the metadata for each movie using a *dictionary comprehension* (which is a lot like a list comprehension in Python, but generates key-value pairs in a dictionary instead!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_lookup = {md[ID_LINK]: md for md in movie_data}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'rotten_tomatoes_link': 'm/0814255',\n",
       " 'movie_title': 'Percy Jackson & the Olympians: The Lightning Thief',\n",
       " 'movie_info': \"Always trouble-prone, the life of teenager Percy Jackson (Logan Lerman) gets a lot more complicated when he learns he's the son of the Greek god Poseidon. At a training ground for the children of deities, Percy learns to harness his divine powers and prepare for the adventure of a lifetime: he must prevent a feud among the Olympians from erupting into a devastating war on Earth, and rescue his mother from the clutches of Hades, god of the underworld.\",\n",
       " 'critics_consensus': 'Though it may seem like just another Harry Potter knockoff, Percy Jackson benefits from a strong supporting cast, a speedy plot, and plenty of fun with Greek mythology.',\n",
       " 'content_rating': 'PG',\n",
       " 'genres': 'Action & Adventure, Comedy, Drama, Science Fiction & Fantasy',\n",
       " 'directors': 'Chris Columbus',\n",
       " 'authors': 'Craig Titley, Chris Columbus, Rick Riordan',\n",
       " 'actors': \"Logan Lerman, Brandon T. Jackson, Alexandra Daddario, Jake Abel, Sean Bean, Pierce Brosnan, Steve Coogan, Rosario Dawson, Melina Kanakaredes, Catherine Keener, Kevin Mckidd, Joe Pantoliano, Uma Thurman, Ray Winstone, Julian Richings, Bonita Friedericy, Annie Ilonzeh, Tania Saulnier, Marie Avgeropoulos, Luisa D'Oliveira, Christie Laing, Marielle Jaffe, Elisa King, Chrystal Tisiga, Alexis Knapp, Charlie Gallant, Chelan Simmons, Andrea Brooks, Natassia Malthe, Max Van Ville, Serinda Swan, Dimitri Lekkos, Ona Grauer, Stefanie von Pfetten, Conrad Coates, Erica Cerra, Dylan Neal, Luke Camilleri, Holly Hougham, Ina Geraldine, Raquel Riskin, Yusleidis Oquendo, Janine Edwards, Valerie Tian, Violet Columbus, Sarah Smyth, Merritt Patterson, Julie Luck, Andrea Day, John Stewart, Suzanne Ristic, Deejay Jackson, Matthew Garrick, Stan Carp, Suzanna Ristic, Richard Harmon, Maria Olsen, Robin Lemon, Doyle Devereux, Tom Pickett, VJ Delos-Reyes, Tim Aas, Keith Dallas, Spencer Atkinson, Maya Washington, Loyd Bateman, Victor Ayala, Zane Holtz, Eli Zagoudakis, Matt Reimer, Rob Hayter, Lloyd Bateman, Shawn Beaton, Jarod Joseph, Reilly Dolman, Paul Cummings, Julie Brar, Dejan Loyola, Damian Arman, Mario Casoria, Dorla Bell, Carolyn Adair (II), Jade Pawluk, G. Patrick Currie, Darian Arman, Mariela Zapata, David L. Smith\",\n",
       " 'original_release_date': '2010-02-12',\n",
       " 'streaming_release_date': '2015-11-25',\n",
       " 'runtime': '119',\n",
       " 'production_company': '20th Century Fox',\n",
       " 'tomatometer_status': 'Rotten',\n",
       " 'tomatometer_rating': '49',\n",
       " 'tomatometer_count': '149',\n",
       " 'audience_status': 'Spilled',\n",
       " 'audience_rating': '53',\n",
       " 'audience_count': '254421',\n",
       " 'tomatometer_top_critics_count': '43',\n",
       " 'tomatometer_fresh_critics_count': '73',\n",
       " 'tomatometer_rotten_critics_count': '76'}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie_lookup['m/0814255']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "m/star_wars_episode_vii_the_force_awakens 48\n",
      "m/solo_a_star_wars_story 46\n",
      "m/suicide_squad_2016 45\n",
      "m/star_wars_the_rise_of_skywalker 44\n",
      "m/spider_man_far_from_home 43\n",
      "m/spider_man_homecoming 42\n",
      "m/ready_player_one 42\n",
      "m/shazam 42\n",
      "m/spotlight_2015 41\n",
      "m/star_wars_the_last_jedi 41\n",
      "m/ready_or_not_2019 37\n",
      "m/star_wars_episode_iii_revenge_of_the_sith 37\n",
      "m/roma_2018 36\n",
      "m/spider_man_into_the_spider_verse 36\n",
      "m/star_trek_11 35\n",
      "m/rocketman_2019 34\n",
      "m/room_2015 34\n",
      "m/split_2017 33\n",
      "m/red_sparrow 33\n",
      "m/sully 33\n",
      "m/rogue_one_a_star_wars_story 31\n",
      "m/sin_city 31\n",
      "m/prometheus_2012 31\n",
      "m/steve_jobs_2015 30\n",
      "m/joker_2019 29\n",
      "m/skyfall 29\n",
      "m/prisoners_2013 29\n",
      "m/shrek_3 29\n",
      "m/richard_jewell 28\n",
      "m/super_8 28\n",
      "m/slumdog_millionaire 28\n",
      "m/spiderman_2 28\n",
      "m/son_of_saul 28\n",
      "m/scott_pilgrims_vs_the_world 28\n",
      "m/san_andreas 27\n",
      "m/star_trek_beyond 27\n",
      "m/silver_linings_playbook 27\n",
      "m/prince_of_persia_sands_of_time 26\n",
      "m/sicario_2015 26\n",
      "m/side_effects_2013 26\n",
      "m/once_upon_a_time_in_hollywood 26\n",
      "m/snowden 26\n",
      "m/avengers_endgame 26\n",
      "m/sideways 26\n",
      "m/sonic_the_hedgehog_2020 25\n",
      "m/a_star_is_born_2018 25\n",
      "m/red_dragon 25\n",
      "m/sorry_to_bother_you_2018 25\n",
      "m/rise_of_the_planet_of_the_apes 25\n",
      "m/shrek_2 25\n",
      "m/spectre_2015 25\n",
      "m/snowpiercer 25\n",
      "m/spiderman 25\n",
      "m/12_years_a_slave 24\n",
      "m/spiderman_3 24\n",
      "m/the_lion_king_2019 24\n",
      "m/captain_marvel 24\n",
      "m/sunshine 24\n",
      "m/speed_racer 24\n",
      "m/saving_mr_banks_2013 23\n",
      "m/seven_psychopaths 23\n",
      "m/star_trek_into_darkness 23\n",
      "m/yesterday_2019 23\n",
      "m/portrait_of_a_lady_on_fire 23\n",
      "m/spy_2015 23\n",
      "m/selma 23\n",
      "m/stuber 23\n",
      "m/snow_white_and_the_huntsman 23\n",
      "m/beauty_and_the_beast_2017 23\n",
      "m/suburbicon 23\n",
      "m/oceans_8 23\n",
      "m/shame_2011 23\n",
      "m/lady_bird 23\n",
      "m/arrival_2016 23\n",
      "m/blade_runner_2049 23\n",
      "m/midsommar 22\n",
      "m/guardians_of_the_galaxy 22\n",
      "m/skyscraper_2018 22\n",
      "m/the_lego_movie_2_the_second_part 22\n",
      "m/blackkklansman 22\n",
      "m/t2_trainspotting 22\n",
      "m/somewhere_2010 22\n",
      "m/birds_of_prey_2020 22\n",
      "m/soloist 22\n",
      "m/get_out 22\n",
      "m/dunkirk_2017 22\n",
      "m/bohemian_rhapsody 22\n",
      "m/sixth_sense 22\n",
      "m/possession 22\n",
      "m/knives_out 22\n",
      "m/rock_of_ages_2012 21\n",
      "m/glass_2019 21\n",
      "m/shaun_of_the_dead 21\n",
      "m/moonlight_2016 21\n",
      "m/1917_2019 21\n",
      "m/district_9 21\n",
      "m/superman_man_of_steel 21\n",
      "m/toy_story_4 21\n",
      "m/us_2019 21\n",
      "m/star_wars_episode_i_the_phantom_menace 21\n"
     ]
    }
   ],
   "source": [
    "num_reviews_by_movie = Counter(rd[ID_LINK] for rd in review_data)\n",
    "top_movies = num_reviews_by_movie.most_common()\n",
    "for movie_title, count in top_movies[:100]:\n",
    "    print(movie_title, count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercise** What do we notice about the movies here? What's present and what's absent? What gets the most reviews?\n",
    "\n",
    "That's a lot of movies! Can we just pull out the comedies to explore those more? I'm going to generate a *set* of the movie IDs for movies marked as comedies. A set keeps track of distinct elements in a way that makes it quick to check whether or not something is in the set, but without preserving order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of comedies: 5674\n"
     ]
    }
   ],
   "source": [
    "comedy_ids = set([m[ID_LINK] for m in movie_data if 'Comedy' in m['genres']])\n",
    "print(\"Number of comedies:\", len(comedy_ids))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's check which genres this pulled out:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Comedy', 1263), ('Comedy, Drama', 863), ('Comedy, Drama, Romance', 312), ('Comedy, Romance', 273), ('Art House & International, Comedy, Drama', 268), ('Action & Adventure, Comedy', 180), ('Comedy, Kids & Family', 125), ('Comedy, Horror', 96), ('Art House & International, Comedy', 93), ('Action & Adventure, Comedy, Drama', 87), ('Comedy, Drama, Mystery & Suspense', 81), ('Comedy, Science Fiction & Fantasy', 66), ('Animation, Comedy, Kids & Family', 65), ('Art House & International, Comedy, Drama, Romance', 63), ('Classics, Comedy, Drama', 61), ('Classics, Comedy', 59), ('Action & Adventure, Comedy, Science Fiction & Fantasy', 55), ('Comedy, Drama, Musical & Performing Arts', 49), ('Classics, Comedy, Drama, Romance', 46), ('Comedy, Mystery & Suspense', 42), ('Classics, Comedy, Romance', 42), ('Action & Adventure, Animation, Comedy, Kids & Family', 40), ('Comedy, Musical & Performing Arts', 40), ('Action & Adventure, Comedy, Kids & Family', 38), ('Comedy, Drama, Kids & Family', 36), ('Comedy, Horror, Science Fiction & Fantasy', 35), ('Comedy, Drama, Science Fiction & Fantasy', 34), ('Action & Adventure, Comedy, Mystery & Suspense', 32), ('Comedy, Kids & Family, Science Fiction & Fantasy', 31), ('Classics, Comedy, Musical & Performing Arts, Romance', 29), ('Action & Adventure, Comedy, Drama, Mystery & Suspense', 28), ('Action & Adventure, Art House & International, Comedy', 25), ('Art House & International, Comedy, Drama, Mystery & Suspense', 22), ('Animation, Comedy', 21), ('Art House & International, Comedy, Romance', 20), ('Comedy, Documentary', 19), ('Classics, Comedy, Musical & Performing Arts', 18), ('Comedy, Documentary, Special Interest', 18), ('Action & Adventure, Comedy, Kids & Family, Science Fiction & Fantasy', 18), ('Action & Adventure, Animation, Comedy', 18), ('Comedy, Horror, Mystery & Suspense', 17), ('Comedy, Television', 14), ('Action & Adventure, Comedy, Horror', 14), ('Comedy, Musical & Performing Arts, Romance', 14), ('Classics, Comedy, Drama, Musical & Performing Arts', 14), ('Action & Adventure, Comedy, Romance', 14), ('Art House & International, Comedy, Horror', 14), ('Action & Adventure, Art House & International, Comedy, Drama, Mystery & Suspense', 13), ('Comedy, Drama, Musical & Performing Arts, Romance', 12), ('Art House & International, Comedy, Drama, Musical & Performing Arts', 12), ('Classics, Comedy, Western', 12), ('Comedy, Drama, Gay & Lesbian', 11), ('Action & Adventure, Comedy, Drama, Romance', 11), ('Action & Adventure, Animation, Comedy, Kids & Family, Science Fiction & Fantasy', 11), ('Comedy, Drama, Special Interest', 11), ('Comedy, Science Fiction & Fantasy, Romance', 11), ('Comedy, Kids & Family, Television', 10), ('Classics, Comedy, Drama, Musical & Performing Arts, Romance', 10), ('Comedy, Drama, Science Fiction & Fantasy, Romance', 10), ('Action & Adventure, Classics, Comedy, Drama', 10), ('Comedy, Drama, Sports & Fitness', 9), ('Comedy, Special Interest', 9), ('Action & Adventure, Comedy, Drama, Kids & Family', 9), ('Animation, Comedy, Kids & Family, Science Fiction & Fantasy', 9), ('Animation, Comedy, Drama', 9), ('Action & Adventure, Art House & International, Comedy, Drama', 8), ('Comedy, Gay & Lesbian', 8), ('Comedy, Documentary, Drama, Special Interest', 8), ('Classics, Comedy, Drama, Mystery & Suspense', 8), ('Art House & International, Comedy, Drama, Special Interest', 7), ('Action & Adventure, Comedy, Western', 7), ('Comedy, Documentary, Television', 7), ('Action & Adventure, Classics, Comedy, Drama, Mystery & Suspense', 7), ('Action & Adventure, Comedy, Kids & Family, Mystery & Suspense', 7), ('Comedy, Kids & Family, Romance', 7), ('Comedy, Documentary, Musical & Performing Arts', 7), ('Action & Adventure, Comedy, Horror, Science Fiction & Fantasy', 7), ('Comedy, Drama, Television', 7), ('Comedy, Documentary, Special Interest, Television', 6), ('Comedy, Drama, Horror', 6), ('Action & Adventure, Comedy, Drama, Science Fiction & Fantasy', 6), ('Action & Adventure, Comedy, Mystery & Suspense, Science Fiction & Fantasy', 6), ('Comedy, Drama, Romance, Gay & Lesbian', 6), ('Classics, Comedy, Drama, Science Fiction & Fantasy', 6), ('Art House & International, Comedy, Drama, Science Fiction & Fantasy', 6), ('Comedy, Drama, Kids & Family, Science Fiction & Fantasy', 6), ('Art House & International, Comedy, Drama, Musical & Performing Arts, Romance', 6), ('Classics, Comedy, Kids & Family', 6), ('Art House & International, Classics, Comedy, Drama, Romance', 6), ('Comedy, Drama, Horror, Mystery & Suspense', 5), ('Action & Adventure, Classics, Comedy', 5), ('Art House & International, Comedy, Mystery & Suspense', 5), ('Classics, Comedy, Mystery & Suspense', 5), ('Classics, Comedy, Horror, Science Fiction & Fantasy', 5), ('Comedy, Western', 5), ('Art House & International, Comedy, Musical & Performing Arts', 4), ('Comedy, Musical & Performing Arts, Science Fiction & Fantasy', 4), ('Action & Adventure, Art House & International, Comedy, Horror', 4), ('Comedy, Horror, Mystery & Suspense, Science Fiction & Fantasy', 4), ('Comedy, Horror, Romance', 4), ('Classics, Comedy, Drama, Kids & Family, Musical & Performing Arts', 4), ('Comedy, Horror, Musical & Performing Arts', 4), ('Comedy, Sports & Fitness', 4), ('Art House & International, Comedy, Science Fiction & Fantasy, Romance', 4), ('Art House & International, Comedy, Documentary, Drama, Special Interest', 4), ('Art House & International, Classics, Comedy, Drama', 4), ('Classics, Comedy, Kids & Family, Science Fiction & Fantasy', 4), ('Art House & International, Comedy, Science Fiction & Fantasy', 4), ('Comedy, Drama, Mystery & Suspense, Science Fiction & Fantasy', 4), ('Classics, Comedy, Science Fiction & Fantasy', 4), ('Comedy, Documentary, Musical & Performing Arts, Special Interest', 4), ('Comedy, Kids & Family, Musical & Performing Arts', 4), ('Comedy, Special Interest, Romance', 4), ('Action & Adventure, Classics, Comedy, Drama, Romance', 4), ('Art House & International, Comedy, Drama, Kids & Family', 4), ('Action & Adventure, Art House & International, Comedy, Drama, Romance', 4), ('Art House & International, Comedy, Drama, Science Fiction & Fantasy, Romance', 4), ('Action & Adventure, Animation, Comedy, Science Fiction & Fantasy', 4), ('Art House & International, Comedy, Drama, Mystery & Suspense, Romance', 3), ('Comedy, Cult Movies', 3), ('Comedy, Drama, Kids & Family, Romance', 3), ('Action & Adventure, Comedy, Kids & Family, Musical & Performing Arts', 3), ('Action & Adventure, Comedy, Horror, Mystery & Suspense', 3), ('Action & Adventure, Art House & International, Comedy, Mystery & Suspense', 3), ('Action & Adventure, Animation, Art House & International, Comedy', 3), ('Comedy, Mystery & Suspense, Romance', 3), ('Action & Adventure, Classics, Comedy, Kids & Family, Science Fiction & Fantasy', 3), ('Animation, Comedy, Drama, Kids & Family', 3), ('Animation, Comedy, Kids & Family, Musical & Performing Arts', 3), ('Classics, Comedy, Kids & Family, Musical & Performing Arts', 3), ('Action & Adventure, Comedy, Kids & Family, Romance', 3), ('Comedy, Drama, Kids & Family, Musical & Performing Arts', 3), ('Comedy, Kids & Family, Special Interest', 3), ('Action & Adventure, Art House & International, Comedy, Romance', 3), ('Comedy, Mystery & Suspense, Science Fiction & Fantasy', 3), ('Action & Adventure, Comedy, Cult Movies', 3), ('Classics, Comedy, Drama, Science Fiction & Fantasy, Romance', 3), ('Animation, Comedy, Kids & Family, Special Interest', 3), ('Art House & International, Comedy, Musical & Performing Arts, Romance', 3), ('Classics, Comedy, Musical & Performing Arts, Western', 3), ('Comedy, Musical & Performing Arts, Mystery & Suspense, Science Fiction & Fantasy', 2), ('Action & Adventure, Comedy, Drama, Western', 2), ('Comedy, Science Fiction & Fantasy, Special Interest', 2), ('Art House & International, Comedy, Kids & Family, Science Fiction & Fantasy', 2), ('Comedy, Cult Movies, Horror, Science Fiction & Fantasy', 2), ('Animation, Art House & International, Comedy, Drama', 2), ('Art House & International, Comedy, Special Interest', 2), ('Action & Adventure, Comedy, Documentary', 2), ('Action & Adventure, Animation, Comedy, Drama, Kids & Family', 2), ('Art House & International, Classics, Comedy, Musical & Performing Arts', 2), ('Action & Adventure, Classics, Comedy, Drama, Musical & Performing Arts', 2), ('Comedy, Drama, Mystery & Suspense, Romance', 2), ('Animation, Art House & International, Comedy, Kids & Family', 2), ('Action & Adventure, Art House & International, Comedy, Drama, Horror', 2), ('Comedy, Drama, Musical & Performing Arts, Special Interest', 2), ('Action & Adventure, Art House & International, Comedy, Documentary, Drama', 2), ('Art House & International, Comedy, Documentary, Drama', 2), ('Action & Adventure, Comedy, Kids & Family, Television', 2), ('Animation, Art House & International, Comedy, Drama, Science Fiction & Fantasy', 2), ('Comedy, Drama, Western', 2), ('Action & Adventure, Classics, Comedy, Drama, Mystery & Suspense, Romance', 2), ('Classics, Comedy, Drama, Mystery & Suspense, Romance', 2), ('Art House & International, Comedy, Drama, Television', 2), ('Action & Adventure, Comedy, Drama, Musical & Performing Arts', 2), ('Action & Adventure, Classics, Comedy, Mystery & Suspense', 2), ('Action & Adventure, Classics, Comedy, Western, Romance', 2), ('Comedy, Documentary, Science Fiction & Fantasy, Special Interest', 2), ('Action & Adventure, Art House & International, Comedy, Mystery & Suspense, Science Fiction & Fantasy', 2), ('Art House & International, Classics, Comedy, Drama, Science Fiction & Fantasy', 2), ('Action & Adventure, Classics, Comedy, Horror', 2), ('Classics, Comedy, Horror', 2), ('Animation, Comedy, Science Fiction & Fantasy', 2), ('Animation, Art House & International, Comedy', 2), ('Art House & International, Comedy, Drama, Sports & Fitness', 2), ('Classics, Comedy, Musical & Performing Arts, Western, Romance', 2), ('Art House & International, Comedy, Drama, Horror', 2), ('Classics, Comedy, Horror, Mystery & Suspense', 2), ('Comedy, Cult Movies, Drama', 2), ('Comedy, Romance, Gay & Lesbian', 2), ('Action & Adventure, Classics, Comedy, Western', 2), ('Art House & International, Comedy, Horror, Science Fiction & Fantasy', 2), ('Comedy, Drama, Kids & Family, Sports & Fitness', 2), ('Action & Adventure, Art House & International, Comedy, Drama, Musical & Performing Arts, Romance', 2), ('Comedy, Drama, Kids & Family, Television', 2), ('Classics, Comedy, Drama, Kids & Family', 2), ('Comedy, Musical & Performing Arts, Gay & Lesbian', 2), ('Action & Adventure, Comedy, Drama, Mystery & Suspense, Romance', 2), ('Comedy, Documentary, Special Interest, Sports & Fitness', 2), ('Classics, Comedy, Drama, Musical & Performing Arts, Science Fiction & Fantasy', 2), ('Classics, Comedy, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 2), ('Comedy, Drama, Musical & Performing Arts, Mystery & Suspense', 2), ('Action & Adventure, Classics, Comedy, Kids & Family', 2), ('Action & Adventure, Art House & International, Classics, Comedy', 2), ('Action & Adventure, Comedy, Cult Movies, Western', 2), ('Classics, Comedy, Drama, Horror, Mystery & Suspense', 2), ('Art House & International, Comedy, Drama, Romance, Gay & Lesbian', 2), ('Comedy, Horror, Kids & Family', 2), ('Action & Adventure, Comedy, Mystery & Suspense, Romance', 2), ('Comedy, Kids & Family, Science Fiction & Fantasy, Romance', 1), ('Comedy, Horror, Kids & Family, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Musical & Performing Arts', 1), ('Action & Adventure, Comedy, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Action & Adventure, Classics, Comedy, Drama, Musical & Performing Arts, Science Fiction & Fantasy, Romance', 1), ('Animation, Comedy, Musical & Performing Arts, Special Interest', 1), ('Action & Adventure, Animation, Comedy, Horror, Mystery & Suspense', 1), ('Art House & International, Comedy, Documentary, Drama, Kids & Family, Special Interest', 1), ('Comedy, Horror, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Action & Adventure, Classics, Comedy, Musical & Performing Arts', 1), ('Art House & International, Comedy, Horror, Mystery & Suspense', 1), ('Comedy, Mystery & Suspense, Science Fiction & Fantasy, Romance', 1), ('Art House & International, Comedy, Drama, Romance, Sports & Fitness', 1), ('Animation, Classics, Comedy, Horror, Kids & Family', 1), ('Action & Adventure, Comedy, Mystery & Suspense, Science Fiction & Fantasy, Television', 1), ('Animation, Comedy, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy, Romance', 1), ('Animation, Art House & International, Comedy, Drama, Kids & Family, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Special Interest', 1), ('Art House & International, Comedy, Drama, Horror, Science Fiction & Fantasy', 1), ('Animation, Anime & Manga, Comedy, Romance', 1), ('Action & Adventure, Classics, Comedy, Kids & Family, Romance', 1), ('Classics, Comedy, Kids & Family, Romance', 1), ('Action & Adventure, Comedy, Kids & Family, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Comedy, Documentary, Drama, Television', 1), ('Action & Adventure, Animation, Comedy, Drama', 1), ('Animation, Comedy, Musical & Performing Arts', 1), ('Comedy, Documentary, Drama, Special Interest, Romance', 1), ('Comedy, Documentary, Drama, Romance', 1), ('Art House & International, Comedy, Drama, Horror, Musical & Performing Arts', 1), ('Action & Adventure, Animation, Art House & International, Comedy, Science Fiction & Fantasy', 1), ('Animation, Comedy, Science Fiction & Fantasy, Television', 1), ('Art House & International, Comedy, Kids & Family', 1), ('Action & Adventure, Art House & International, Classics, Comedy, Cult Movies, Horror, Science Fiction & Fantasy', 1), ('Art House & International, Classics, Comedy, Drama, Musical & Performing Arts, Science Fiction & Fantasy, Romance', 1), ('Comedy, Documentary, Special Interest, Television, Sports & Fitness', 1), ('Classics, Comedy, Drama, Sports & Fitness', 1), ('Animation, Classics, Comedy, Kids & Family', 1), ('Action & Adventure, Art House & International, Comedy, Musical & Performing Arts, Mystery & Suspense, Romance', 1), ('Action & Adventure, Comedy, Drama, Kids & Family, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Action & Adventure, Classics, Comedy, Drama, Musical & Performing Arts, Mystery & Suspense', 1), ('Action & Adventure, Comedy, Drama, Horror', 1), ('Action & Adventure, Comedy, Documentary, Sports & Fitness', 1), ('Comedy, Musical & Performing Arts, Television', 1), ('Art House & International, Comedy, Documentary, Drama, Musical & Performing Arts', 1), ('Classics, Comedy, Drama, Western, Romance', 1), ('Art House & International, Comedy, Documentary, Special Interest, Television', 1), ('Action & Adventure, Classics, Comedy, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Horror, Romance', 1), ('Comedy, Documentary, Drama', 1), ('Action & Adventure, Art House & International, Comedy, Drama, Kids & Family', 1), ('Animation, Comedy, Horror, Romance', 1), ('Classics, Comedy, Documentary, Sports & Fitness', 1), ('Action & Adventure, Art House & International, Classics, Comedy, Documentary, Drama', 1), ('Action & Adventure, Art House & International, Comedy, Cult Movies, Drama', 1), ('Classics, Comedy, Drama, Musical & Performing Arts, Mystery & Suspense', 1), ('Action & Adventure, Comedy, Science Fiction & Fantasy, Special Interest', 1), ('Action & Adventure, Art House & International, Comedy, Drama, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Action & Adventure, Art House & International, Comedy, Drama, Gay & Lesbian', 1), ('Classics, Comedy, Cult Movies, Horror', 1), ('Animation, Comedy, Special Interest', 1), ('Comedy, Science Fiction & Fantasy, Romance, Sports & Fitness', 1), ('Action & Adventure, Animation, Classics, Comedy, Kids & Family, Musical & Performing Arts', 1), ('Art House & International, Comedy, Drama, Kids & Family, Romance', 1), ('Classics, Comedy, Cult Movies, Horror, Mystery & Suspense', 1), ('Comedy, Cult Movies, Drama, Science Fiction & Fantasy', 1), ('Art House & International, Comedy, Gay & Lesbian', 1), ('Art House & International, Comedy, Special Interest, Romance', 1), ('Action & Adventure, Comedy, Drama, Kids & Family, Mystery & Suspense', 1), ('Action & Adventure, Art House & International, Comedy, Science Fiction & Fantasy', 1), ('Classics, Comedy, Drama, Special Interest', 1), ('Classics, Comedy, Drama, Kids & Family, Romance', 1), ('Comedy, Cult Movies, Documentary, Drama, Musical & Performing Arts, Special Interest', 1), ('Art House & International, Classics, Comedy', 1), ('Comedy, Documentary, Kids & Family', 1), ('Comedy, Horror, Kids & Family, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Classics, Comedy, Science Fiction & Fantasy, Romance', 1), ('Comedy, Musical & Performing Arts, Western', 1), ('Animation, Comedy, Kids & Family, Musical & Performing Arts, Television', 1), ('Art House & International, Classics, Comedy, Drama, Mystery & Suspense', 1), ('Comedy, Horror, Mystery & Suspense, Television', 1), ('Classics, Comedy, Special Interest', 1), ('Comedy, Drama, Horror, Kids & Family', 1), ('Comedy, Mystery & Suspense, Special Interest', 1), ('Classics, Comedy, Drama, Western', 1), ('Action & Adventure, Comedy, Drama, Musical & Performing Arts, Romance', 1), ('Art House & International, Comedy, Drama, Science Fiction & Fantasy, Special Interest', 1), ('Action & Adventure, Comedy, Drama, Science Fiction & Fantasy, Television', 1), ('Art House & International, Comedy, Musical & Performing Arts, Science Fiction & Fantasy, Television, Romance', 1), ('Action & Adventure, Comedy, Cult Movies, Mystery & Suspense', 1), ('Classics, Comedy, Drama, Mystery & Suspense, Science Fiction & Fantasy, Romance', 1), ('Action & Adventure, Art House & International, Comedy, Drama, Science Fiction & Fantasy', 1), ('Animation, Comedy, Kids & Family, Faith & Spirituality', 1), ('Action & Adventure, Comedy, Drama, Mystery & Suspense, Western', 1), ('Classics, Comedy, Drama, Mystery & Suspense, Special Interest, Romance', 1), ('Comedy, Drama, Kids & Family, Science Fiction & Fantasy, Television', 1), ('Action & Adventure, Comedy, Drama, Horror, Mystery & Suspense, Science Fiction & Fantasy, Romance', 1), ('Action & Adventure, Animation, Comedy, Drama, Kids & Family, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Cult Movies, Drama, Musical & Performing Arts', 1), ('Action & Adventure, Animation, Comedy, Kids & Family, Musical & Performing Arts', 1), ('Art House & International, Classics, Comedy, Gay & Lesbian', 1), ('Art House & International, Comedy, Drama, Television, Romance', 1), ('Animation, Classics, Comedy, Kids & Family, Science Fiction & Fantasy', 1), ('Classics, Comedy, Kids & Family, Mystery & Suspense', 1), ('Action & Adventure, Art House & International, Comedy, Kids & Family', 1), ('Action & Adventure, Comedy, Sports & Fitness', 1), ('Animation, Classics, Comedy, Kids & Family, Special Interest', 1), ('Comedy, Cult Movies, Horror, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Comedy, Drama, Horror, Romance', 1), ('Action & Adventure, Comedy, Documentary, Musical & Performing Arts', 1), ('Classics, Comedy, Drama, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Comedy, Drama, Horror, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Comedy, Drama, Science Fiction & Fantasy, Gay & Lesbian', 1), ('Comedy, Drama, Faith & Spirituality', 1), ('Comedy, Drama, Horror, Special Interest', 1), ('Animation, Comedy, Drama, Kids & Family, Musical & Performing Arts', 1), ('Comedy, Documentary, Drama, Kids & Family, Faith & Spirituality', 1), ('Animation, Comedy, Drama, Science Fiction & Fantasy', 1), ('Comedy, Kids & Family, Musical & Performing Arts, Television, Romance', 1), ('Action & Adventure, Classics, Comedy, Romance', 1), ('Art House & International, Comedy, Drama, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Art House & International, Comedy, Drama, Musical & Performing Arts, Special Interest', 1), ('Art House & International, Comedy, Documentary, Drama, Special Interest, Faith & Spirituality', 1), ('Comedy, Drama, Romance, Gay & Lesbian, Sports & Fitness', 1), ('Action & Adventure, Classics, Comedy, Cult Movies, Science Fiction & Fantasy', 1), ('Classics, Comedy, Kids & Family, Television', 1), ('Action & Adventure, Art House & International, Comedy, Cult Movies, Horror, Science Fiction & Fantasy', 1), ('Animation, Comedy, Horror, Science Fiction & Fantasy', 1), ('Comedy, Musical & Performing Arts, Television, Romance', 1), ('Classics, Comedy, Drama, Musical & Performing Arts, Western', 1), ('Art House & International, Comedy, Musical & Performing Arts, Sports & Fitness', 1), ('Action & Adventure, Animation, Comedy, Cult Movies, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Drama, Science Fiction & Fantasy, Romance', 1), ('Action & Adventure, Art House & International, Comedy, Drama, Musical & Performing Arts', 1), ('Animation, Classics, Comedy, Kids & Family, Musical & Performing Arts, Television', 1), ('Comedy, Drama, Kids & Family, Mystery & Suspense', 1), ('Classics, Comedy, Cult Movies, Horror, Musical & Performing Arts', 1), ('Art House & International, Comedy, Drama, Kids & Family, Musical & Performing Arts, Romance', 1), ('Action & Adventure, Comedy, Drama, Kids & Family, Science Fiction & Fantasy', 1), ('Comedy, Drama, Kids & Family, Musical & Performing Arts, Television', 1), ('Comedy, Documentary, Faith & Spirituality', 1), ('Action & Adventure, Comedy, Science Fiction & Fantasy, Romance', 1), ('Animation, Anime & Manga, Art House & International, Comedy, Kids & Family', 1), ('Art House & International, Comedy, Cult Movies, Drama, Mystery & Suspense', 1), ('Animation, Classics, Comedy, Kids & Family, Mystery & Suspense', 1), ('Comedy, Horror, Musical & Performing Arts, Television', 1), ('Comedy, Kids & Family, Western', 1), ('Comedy, Television, Romance', 1), ('Action & Adventure, Comedy, Kids & Family, Science Fiction & Fantasy, Television', 1), ('Action & Adventure, Classics, Comedy, Science Fiction & Fantasy', 1), ('Art House & International, Comedy, Cult Movies, Musical & Performing Arts', 1), ('Comedy, Cult Movies, Drama, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Art House & International, Comedy, Drama, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Action & Adventure, Classics, Comedy, Drama, Kids & Family, Special Interest', 1), ('Art House & International, Comedy, Science Fiction & Fantasy, Gay & Lesbian', 1), ('Comedy, Cult Movies, Horror', 1), ('Classics, Comedy, Drama, Kids & Family, Science Fiction & Fantasy', 1), ('Animation, Classics, Comedy, Drama, Kids & Family', 1), ('Classics, Comedy, Cult Movies, Documentary, Drama', 1), ('Action & Adventure, Animation, Comedy, Kids & Family, Mystery & Suspense', 1), ('Animation, Comedy, Documentary, Drama, Special Interest, Romance', 1), ('Comedy, Kids & Family, Musical & Performing Arts, Television', 1), ('Action & Adventure, Animation, Comedy, Musical & Performing Arts', 1), ('Action & Adventure, Animation, Comedy, Drama, Kids & Family, Musical & Performing Arts', 1), ('Action & Adventure, Classics, Comedy, Drama, Musical & Performing Arts, Western, Romance', 1), ('Action & Adventure, Comedy, Horror, Science Fiction & Fantasy, Special Interest', 1), ('Art House & International, Comedy, Drama, Kids & Family, Science Fiction & Fantasy', 1), ('Classics, Comedy, Cult Movies, Horror, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Animation, Classics, Comedy, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Art House & International, Classics, Comedy, Horror, Science Fiction & Fantasy', 1), ('Comedy, Drama, Faith & Spirituality, Sports & Fitness', 1), ('Comedy, Science Fiction & Fantasy, Special Interest, Romance', 1), ('Comedy, Musical & Performing Arts, Special Interest', 1), ('Animation, Comedy, Kids & Family, Musical & Performing Arts, Romance', 1), ('Action & Adventure, Animation, Comedy, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Art House & International, Comedy, Romance, Gay & Lesbian', 1), ('Classics, Comedy, Musical & Performing Arts, Special Interest, Romance', 1), ('Comedy, Drama, Mystery & Suspense, Science Fiction & Fantasy, Romance', 1), ('Action & Adventure, Art House & International, Comedy, Special Interest', 1), ('Action & Adventure, Comedy, Drama, Musical & Performing Arts, Romance, Gay & Lesbian', 1), ('Comedy, Documentary, Drama, Musical & Performing Arts', 1), ('Action & Adventure, Animation, Comedy, Documentary, Kids & Family', 1), ('Animation, Art House & International, Comedy, Kids & Family, Mystery & Suspense', 1), ('Action & Adventure, Classics, Comedy, Musical & Performing Arts, Romance', 1), ('Action & Adventure, Classics, Comedy, Documentary, Drama, Musical & Performing Arts', 1), ('Classics, Comedy, Kids & Family, Western', 1), ('Action & Adventure, Comedy, Horror, Television', 1), ('Action & Adventure, Animation, Comedy, Kids & Family, Musical & Performing Arts, Romance', 1), ('Action & Adventure, Comedy, Kids & Family, Science Fiction & Fantasy, Romance', 1), ('Action & Adventure, Animation, Classics, Comedy, Kids & Family', 1), ('Classics, Comedy, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Comedy, Musical & Performing Arts, Sports & Fitness', 1), ('Action & Adventure, Comedy, Kids & Family, Musical & Performing Arts, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Kids & Family, Special Interest', 1), ('Comedy, Documentary, Horror', 1), ('Classics, Comedy, Documentary, Musical & Performing Arts, Special Interest', 1), ('Comedy, Documentary, Drama, Romance, Gay & Lesbian', 1), ('Action & Adventure, Comedy, Musical & Performing Arts, Science Fiction & Fantasy, Western', 1), ('Art House & International, Comedy, Science Fiction & Fantasy, Special Interest', 1), ('Art House & International, Comedy, Television, Romance', 1), ('Comedy, Cult Movies, Mystery & Suspense, Science Fiction & Fantasy', 1), ('Comedy, Horror, Kids & Family, Mystery & Suspense', 1), ('Comedy, Drama, Horror, Science Fiction & Fantasy', 1), ('Action & Adventure, Comedy, Horror, Musical & Performing Arts', 1), ('Comedy, Documentary, Kids & Family, Special Interest', 1), ('Classics, Comedy, Drama, Science Fiction & Fantasy, Romance, Faith & Spirituality', 1), ('Comedy, Drama, Mystery & Suspense, Sports & Fitness', 1), ('Art House & International, Comedy, Horror, Science Fiction & Fantasy, Special Interest', 1), ('Art House & International, Comedy, Western', 1)]\n"
     ]
    }
   ],
   "source": [
    "genres = Counter([movie_lookup[c]['genres'] for c in comedy_ids])\n",
    "print(genres.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Whoops, okay, that's not super readable. It looks like because most movies have multiple genres and \"Comedy\" has a lot of overlap, this gives us a huge list of different options. Looking through, it looks like genres are separated by `\", \"`, so let's use that to split them up and then count those!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Comedy', 5674), ('Drama', 2377), ('Romance', 1006), ('Action & Adventure', 806), ('Art House & International', 708), ('Kids & Family', 549), ('Classics', 473), ('Science Fiction & Fantasy', 460), ('Mystery & Suspense', 358), ('Musical & Performing Arts', 337), ('Horror', 271), ('Animation', 240), ('Special Interest', 118), ('Documentary', 109), ('Television', 73), ('Western', 49), ('Gay & Lesbian', 40), ('Cult Movies', 32), ('Sports & Fitness', 31), ('Faith & Spirituality', 7), ('Anime & Manga', 2)]\n"
     ]
    }
   ],
   "source": [
    "genres = Counter()\n",
    "for c in comedy_ids:\n",
    "    genres.update(movie_lookup[c]['genres'].split(', '))\n",
    "print(genres.most_common())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better. There are some weird things we notice (for instance, we have a large Animation category but a small Anime and Manga category), but reassuringly, the number of times Comedy shows up is the same as the number of movies we grabbed. Phew.\n",
    "\n",
    "Let's grab the reviews that go with these movies and verify it seems to be working:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "comedy_reviews = [r for r in review_data if r[ID_LINK] in comedy_ids]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16434\n",
      "{'rotten_tomatoes_link': 'm/men_in_black', 'critic_name': 'Mike Massie', 'top_critic': 'False', 'publisher_name': 'Gone With The Twins', 'review_type': 'Fresh', 'review_score': '9/10', 'review_date': '2020-09-14', 'review_content': \"Choosing to go the route of puppets and primarily practical effects, the film's look remains striking, even after years of advancing computer graphics.\"}\n"
     ]
    }
   ],
   "source": [
    "print(len(comedy_reviews))\n",
    "print(comedy_reviews[1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Yup - Men in Black is an action comedy, so this checks out. Now it's time to featurize the text. Since this is in a highly processed dataset, we're not going to start with much cleaning - let's just see how well it does as it is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [cr[TEXT] for cr in comedy_reviews]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since these review excerpts are very short, it turns out the threshold I recommend for nontrivial-length documents (e.g. .3, .5) aren't going to work well here to remove stopwords. So I'm going to use a small stopword file of my own to help clean out some words I don't anticipate needing today:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a', 'all', 'also', 'am', 'an', 'and', 'are', 'be', 'because', 'been', 'being', 'but', 'by', 'can', 'could', 'did', 'do', 'does', 'every', 'for', 'from', 'had', 'has', 'have', 'i', 'in', 'is', 'its', 'make', 'many', 'may', 'might', 'more', 'most', 'must', 'need', 'new', 'not', 'now', 'of', 'on', 'one', 'other', 'our', 'own', 'shall', 'should', 'than', 'that', 'the', 'their', 'them', 'there', 'these', 'they', 'this', 'those', 'time', 'to', 'was', 'we', 'were', 'what', 'when', 'which', 'who', 'will', 'with', 'would', 'year', 'years', 'you']\n"
     ]
    }
   ],
   "source": [
    "with open('stoplist_en.txt') as stop_file:\n",
    "    stoplist = [line.strip() for line in stop_file]\n",
    "print(stoplist)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is a fairly conservative list - I might have missed some words I later will not be interested in. But for now, let's keep it conservative - we'll also keep any feature that shows up in three distinct review snippets. I'll give my stoplist to my CountVectorizer to proceed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Documents by features: (16434, 9200)\n"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer(input=texts, min_df=3, stop_words=stoplist)\n",
    "review_features = cv.fit_transform(texts)\n",
    "feature_names = cv.get_feature_names_out()\n",
    "# feature_names = cv.get_feature_names() # for older scikit\n",
    "print(\"Documents by features:\", review_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As previously mentioned, CountVectorizers generate sparse matrices - that is, they only represent the entries in our 2D data structure of numbers that are nonzero. For some math we're about to do, I'm going to want the dense matrix, or a representation with all of the zeros where they should be. I'll call `toarray()` to make that happen, then look at how the data looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "190208 words\n",
      "0.1219% nonzero\n",
      "['000', '007', '10', '100', '11', '110', '12', '13', '14', '15']\n",
      "[[0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "dense_review_features = review_features.toarray()\n",
    "print(dense_review_features.sum(), \"words\")\n",
    "nonzero_prop = len(dense_review_features.nonzero()[0])/(dense_review_features.shape[0]*dense_review_features.shape[1])\n",
    "print(\"{:.4f}% nonzero\".format(nonzero_prop*100))\n",
    "\n",
    "print(feature_names[:10])\n",
    "print(dense_review_features[:20,:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, a little over one in a thousand of the entries in our matrix are nonzero - wild! For example, for the first features in our list (\n",
    "\n",
    "**Exercise:** Find the index `i` of the word \"the\" in the features, then look at the counts in each review for that feature by selecting `dense_review_features[:, i]`. Can you figure out how to compute the average value in that matrix? What is it? ([This](https://numpy.org/doc/stable/reference/generated/numpy.mean.html) may help).\n",
    "\n",
    "## Finding interesting documents with lexicons\n",
    "\n",
    "Let's narrow our search further - maybe we're interested in how people talk about money in conjunction with comedies. (Maybe we'll compare that with how it looks for other genres.) Let's start by coming up with a few words that we're interested in, then finding the list of documents that contain those words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'tolist'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-30-6bb2b00d4a01>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmoney_lexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'money'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'earning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmoney_lexicon_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoney_lexicon\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoney_lexicon_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoney_lexicon_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-30-6bb2b00d4a01>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmoney_lexicon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'money'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'earning'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'cash'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'income'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmoney_lexicon_idxs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoney_lexicon\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mw\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mfeature_names\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmoney_lexicon_idxs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfeature_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmoney_lexicon_idxs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'tolist'"
     ]
    }
   ],
   "source": [
    "money_lexicon = ['money', 'earning', 'cash', 'income']\n",
    "money_lexicon_idxs = [feature_names.tolist().index(w) for w in money_lexicon if w in feature_names]\n",
    "print(money_lexicon_idxs)\n",
    "print([feature_names[i] for i in money_lexicon_idxs])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We notice that not all the features we were looking for are actually in our data. If we knew we should have expected a feature that didn't show up, then we could go back through and check our data processing for why documents that should contain that word aren't registering as having that feature...but in this case, I'm not surprised \"income\" isn't something people mention in review snippets, so we won't worry about it. Let's start by just getting the list of reviews that mention any of these three things:\n",
    "\n",
    "(NB: the call to `tolist` will break things in earlier versions of scikit-learn.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reviews_by_lexicon(lexicon, feature_names, feature_matrix, data_entries):\n",
    "    \"\"\"Use the words that show up in a lexicon to find documents with nonzero lexicon items in them\"\"\"\n",
    "    # get all the lexicon indices for the items present\n",
    "    lexicon_idxs = [feature_names.tolist().index(w) for w in lexicon if w in feature_names]\n",
    "    # sum across all the different words for each dictionary (that is, across columns - which are counted in shape[1])\n",
    "    lexicon_sums = np.sum(feature_matrix[:, lexicon_idxs], axis=1)\n",
    "    # find all the indices of documents with nonzero counts\n",
    "    doc_idxs = np.argwhere(lexicon_sums > 0)[:,0]\n",
    "    \n",
    "    return [data_entries[i] for i in doc_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of money docs: 67\n",
      "{'rotten_tomatoes_link': 'm/10009083-land_of_the_lost', 'critic_name': 'Erik Childress', 'top_critic': 'False', 'publisher_name': 'eFilmCritic.com', 'review_type': 'Rotten', 'review_score': '1.5/4', 'review_date': '2009-06-05', 'review_content': 'Land of the Lost will have kids asking if they can just go see Up again. Hopefully mom and dad have a little money left after blowing it on this.'}\n",
      "{'rotten_tomatoes_link': 'm/1188347-mad_money', 'critic_name': 'Tricia Olszewski', 'top_critic': 'False', 'publisher_name': \"Let's Not Listen\", 'review_type': 'Fresh', 'review_score': '', 'review_date': '2008-02-29', 'review_content': \"Keaton and Latifah lend enough intelligence, wit, and charm to their characters that Mad Money often feels like an ovarian Ocean's Eleven.\"}\n",
      "{'rotten_tomatoes_link': 'm/the_hangover_2', 'critic_name': 'Nick Schager', 'top_critic': 'False', 'publisher_name': 'Slant Magazine', 'review_type': 'Rotten', 'review_score': '1/4', 'review_date': '2011-05-25', 'review_content': 'Todd Phillips directs with increased confidence, but in every respect, The Hangover Part II is a cowardly cash-in, devoid of novelty or daring.'}\n",
      "{'rotten_tomatoes_link': 'm/cars_3', 'critic_name': 'James Plath', 'top_critic': 'False', 'publisher_name': 'Family Home Theater', 'review_type': 'Fresh', 'review_score': 'B', 'review_date': '2018-01-16', 'review_content': 'For the first 15 minutes or so Cars 3 seems like a dash-for-the-cash affair. Then Disney does what they do best: they get viewers emotionally involved with the characters.'}\n",
      "{'rotten_tomatoes_link': 'm/pirates_of_the_caribbean_on_stranger_tides', 'critic_name': 'Rene Rodriguez', 'top_critic': 'True', 'publisher_name': 'Miami Herald', 'review_type': 'Rotten', 'review_score': '1/4', 'review_date': '2011-05-18', 'review_content': \"A nonsensical contraption designed simply to take your money. Don't give it up so easily.\"}\n"
     ]
    }
   ],
   "source": [
    "money_docs = find_reviews_by_lexicon(lexicon=money_lexicon,\n",
    "                                     feature_names=feature_names,\n",
    "                                     feature_matrix=dense_review_features,\n",
    "                                     data_entries=comedy_reviews)\n",
    "\n",
    "print(\"Number of money docs:\", len(money_docs))\n",
    "for doc in money_docs[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, we're down to 67 reviews, which is...not much. What if we could expand our lexicon? Unfortunately, brainstorming lexicon words from scratch is kind of hard. Lucky for us, we can write programs to help!\n",
    "\n",
    "Without going into too much detail: this program uses one kind of correlation metric, Spearman rho, to see whether the occurrences of each word in the vocabulary follow a similar pattern to the lexicon counts for our smaller lexicon. It'll sort the resulting words in decreasing order by the amount they're correlated. You can do this with lots of metrics (I often use PMI) with different results, but the general idea is that we can use word correlations to help suggest other lexicon words we might not have come up with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_reviews_by_lexicon(lexicon, feature_names, feature_matrix, data_entries):\n",
    "    \"\"\"Use the words that show up in a lexicon to find documents with nonzero lexicon items in them\"\"\"\n",
    "    # get all the lexicon indices for the items present\n",
    "    lexicon_idxs = [feature_names.tolist().index(w) for w in lexicon if w in feature_names]\n",
    "    # sum across all the different words for each dictionary (that is, across columns - which are counted in shape[1])\n",
    "    lexicon_sums = np.sum(feature_matrix[:, lexicon_idxs], axis=1)\n",
    "    # find all the indices of documents with nonzero counts\n",
    "    doc_idxs = np.argwhere(lexicon_sums > 0)[:,0]\n",
    "    \n",
    "    return [data_entries[i] for i in doc_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_words_by_mi(lexicon, feature_names, feature_matrix):\n",
    "    \"\"\"uses mutual information to find words that are correlated with our lexicon\"\"\"\n",
    "    lexicon_idxs = [feature_names.tolist().index(w) for w in lexicon if w in feature_names]\n",
    "    # we're going to use two labels: 0 = word is absent, 1 = word is present.\n",
    "    # we'll round values higher than 1 to 1 with clip.\n",
    "    lexicon_labels = np.sum(dense_review_features[:, money_lexicon_idxs], axis=1).clip(0,1)\n",
    "    n_features = len(feature_names)\n",
    "    # for each word, check how correlated it is with the lexicon counts\n",
    "    feature_scores = [(mutual_info_score(lexicon_labels, feature_matrix[:,i].clip(0, 1)), feature_names[i]) for i in range(n_features)]\n",
    "    return sorted(feature_scores, reverse=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see what this suggests for our money lexicon (warning, this is slow):\n",
    "**Exercise** Compare using Spearman rho and mutual information to find correlation. Are there any major differences in top suggested words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "money_scores = find_words_by_mi(money_lexicon, feature_names, dense_review_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for score, wd in money_scores[:100]:\n",
    "    print(wd, \"{:.4f}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While I could have removed my \"seed words\" from the list, I like keeping them in there to verify my algorithm is working how I expect - if \"money\" wasn't at the top of the list, that'd tell me I had a bug in my code! Most of these words aren't that interesting to me, but a few might be good to add...\n",
    "\n",
    "**Exercise** Let's add some of these suggested words to our lexicon and see the effect:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_money_lexicon = [\"money\", \"cash\", \"earning\", \"buy\"]\n",
    "new_money_docs = find_reviews_by_lexicon(lexicon=new_money_lexicon,\n",
    "                                     feature_names=feature_names,\n",
    "                                     feature_matrix=dense_review_features,\n",
    "                                     data_entries=comedy_reviews)\n",
    "\n",
    "print(\"Number of new money docs:\", len(new_money_docs))\n",
    "for doc in new_money_docs[:5]:\n",
    "    print(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I find lexicons to be underrated: they're a really helpful tool to make it easy to document a particular filtering or counting task. They're often a pain because they have to be made manually, and since machine learning researchers don't usually count as experts in the domains of the data they study, there's not as much discussion in the places I publish papers about how to do this effectively. However, if you have expertise in the data, you can (and should) use it to help develop things like lexicons to help check and filter things as needed.\n",
    "\n",
    "## Rough topic models for rough-draft datasets\n",
    "\n",
    "When I don't know much about a dataset, one of the first things I'll often do is train an LDA topic model on it - sometimes before many of the steps we've talked about in the other two lessons.\n",
    "\n",
    "Why would I do that? Well, first, let's briefly talk about what an LDA topic model does. If you haven't run into these before, I recommend sources like [Lisa Rhody's Digital Humanities article](http://journalofdigitalhumanities.org/2-1/topic-modeling-and-figurative-language-by-lisa-m-rhody/) and [Ted Underwood's blog post](https://tedunderwood.com/category/methodology/topic-modeling/) to get some of the intuitions. Once you've gotten at the intuition of these models, it can be good to dig into tutorials, like the existing [topic modeling course on Constellate](https://constellate.org/tutorials/topic-modeling) or other variations online, to explore what you can do with these.\n",
    "\n",
    "First, in this context, a *topic* is just a probability distribution of words (for instance, a topic could have high probabilities of the words \"great\", \"cool\", and \"fun\" and low probabilities of the words \"boring\", \"dinosaur\", and \"edward\"). Every topic will have at least some tiny probability of every word in the vocabulary of the text collection, but there should be a small subset of the vocabulary with high probability and very little probability of the majority of the vocabulary. A topic *model* describes a collection of texts using a fixed number of different topics: each document is described as having proportions of each topic, and each topic is described as having proportions of each word.\n",
    "\n",
    "To *infer* a topic model is to run an algorithm that knows the list of documents and the words in them (think of the data in our CountVectorizer - no order information, just word counts) and to try to find a fixed number of topics that can best describe the actual words present in the documents when combined together. Not all documents necessarily have one dominant topic - a document #372 could be 15% about topic 1, 80% about topic 2, and ~5% distributed over everything else. However, our topic model is working well if between topics 1 and 2, we get high probabilities of the words that actually show up in document #372, and likewise for the topics present in each of our other documents.\n",
    "\n",
    "A topic model has two major outputs: topic-word distributions, which describe how often each word shows up in each topic, and document-topic distributions, which describe the topic breakdown of each document. The nice thing is that all we need to infer one of these models is some way to get word counts by document (again, our CountVectorizer is great at that) and some existing code that trains a model.\n",
    "\n",
    "Notably, since finding the \"best\" topics is an impossibly hard math problem, we instead have programs that use randomness and iteration to eventually converge to \"good\" topics. You should expect the outputs of standard topic modeling software to change each time you run it. But that aside, usually you'll see some shuffling of topic order and the order of top words in each topic but a fair amount of consistency in what topics and words are present.\n",
    "\n",
    "Now, hot take time: most people training topic models in Python will probably turn to a library called `gensim`. I'm instead using the implementation that's built into scikit-learn, not because it's better (the interface is actually worse) but because\n",
    "1. we've been using sklearn already, and\n",
    "2. while gensim has nicer interfaces for some parts of this, both scikit-learn and gensim don't train good LDA topic models on normal-size text collections.\n",
    "\n",
    "What? That's right - with the libraries currently available, I do not recommend using Python to train topic models for your actual analysis. Both gensim and scikit-learn use a strategy called batch/online LDA to find the \"best\" topic model for a corpus that is meant to work well for very large collections (think millions of documents). On even tens of thousands, the topics they learn tend to be pretty iffy. Without digging into the math of why, when you train a topic model on a non-massive corpus, you probably want to use something that says \"MCMC\" or \"Gibbs sampling\" in how it does inference. [MALLET](https://mimno.github.io/Mallet/) (a command-line tool) and the R package [topicmodels](https://cran.r-project.org/web/packages/topicmodels/index.html) both support this and will give you better analyses and have plenty of tutorials available online. If you want help getting MALLET set up, check out [Melanie Walsh's tutorial](https://melaniewalsh.github.io/Intro-Cultural-Analytics/05-Text-Analysis/06-Topic-Modeling-Overview.html).\n",
    "\n",
    "Since we're in Python-land for this tutorial and just exploring how to use topic models to notice if something's up with the corpus, we'll make do with what we've got. Let's train a 25-topic model and pull out our document-topic and topic-word information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_topics = 25\n",
    "lda = LatentDirichletAllocation(n_components=n_topics,batch_size=len(comedy_reviews))\n",
    "doc_topic_vecs = lda.fit_transform(review_features)\n",
    "topic_word_vecs = lda.components_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To look at our topics, we generally want to pull out highest-probability words for each topic. We can do this using numpy's `argsort`, which takes in data and, rather than just sorting the data, puts the *indices* of different elements of the data in order based on the values present. So, when we *argsort* the list of word proportions for a particular topic below, we're listing indices of words in our vocabulary in order of how present they are in the topic. (The `[::-1]` syntax is a weird way of saying \"put these elements highest to lowest instead of lowest to highest\".)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "n_words_to_print = 10\n",
    "for topic in range(n_topics):\n",
    "    top_word_idxs = np.argsort(topic_word_vecs[topic])[-n_words_to_print:][::-1]\n",
    "    top_words = [feature_names[i] for i in top_word_idxs]\n",
    "    print(topic, ' '.join(top_words))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, everyone I know has the instinct to say \"Our stoplist is incomplete - let's go back and fix it and then retrain our model again.\" This commences a very long loop of changing the stoplist, then retraining, then changing again, then retraining again...it's one of many pre-processing loops that happens, and it can require revisiting over and over if you change your tokenization or other things about your corpus.\n",
    "\n",
    "I'm here to bear good news: aside from extremely frequent words, most stopwords aren't actually affecting how well your topic model distinguishes documents or themes. They look like they do, because they interfere with your ability to guess what a topic might be about based on the top words, but you can just grab more words and ignore the ones you don't care about instead of retraining. In English, \"the\", \"was\", etc. are likely to be important to remove before training, but most won't affect what happens to the rest of the text...so you can just write a function like the one below to ignore those words after the fact. (I [wrote a paper](https://aclanthology.org/E17-2069/) showing this works out fine for a few different Latin-based languages.)\n",
    "\n",
    "**Exercise** Add some words to the `post_stoplist` and modify `n_words_to_print` until you feel like the topics look distinct. Anything stick out as unusual about the topics?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def print_topic_keys(topic_word_vecs, n_words_to_print=20, post_stoplist=[]):\n",
    "    for topic in range(n_topics):\n",
    "        top_word_idxs = np.argsort(topic_word_vecs[topic])[-n_words_to_print+len(post_stoplist):][::-1]\n",
    "        top_words = [feature_names[i] for i in top_word_idxs if feature_names[i] not in post_stoplist]\n",
    "        print(topic, ' '.join(top_words[:n_words_to_print]))\n",
    "        print()\n",
    "    \n",
    "print_topic_keys(topic_word_vecs, n_words_to_print=20, post_stoplist=['it', 'be', 'at', 'movie', 'film'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generally speaking, these top words can help you start to get at some broad themes -- we expect to see things like rom-coms, or clear positive or negative words, as signals of topics. However, it's worth taking a skim through to see if there's anything unusual in our top words that sets off alarm bells, or any topics where we can't clear discern why that would be a topic. Again, our topic model is probably not super great on this data since we're only using a few thousand documents, but we might notice some words that are weird as high-probability parts of topics. In those cases, what we should do is look at the documents with the highest proportion of a topic and see if we can figure out in what context those words are showing up.\n",
    "\n",
    "**Exercise** Pick a couple of topics that look odd and inspect their top documents using the code below. See if you can figure out which documents are producing the words that looked odd, and whether the cause of their oddness is benign or something that might require further intervention."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_top_docs_by_topic(docs, doc_topic_vecs, topic, n_top_docs=50):\n",
    "    doc_idxs = doc_topic_vecs[:,topic].argsort()[:-n_top_docs-1:-1]\n",
    "    for idx in doc_idxs:\n",
    "        print(\"Topic proportion:\", doc_topic_vecs[idx][topic])\n",
    "        print(docs[idx])\n",
    "        print()\n",
    "\n",
    "get_top_docs_by_topic(comedy_reviews, doc_topic_vecs, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Topic models are very good at finding words that show up together, which is actually a perk for us when we're cleaning a text collection: if there's a systematic issue that causes repeated text to appear or that means a subset of the data is fundamentally very different from the rest, the topic model will almost always put the words that indicate that issue together in a topic. Since topic models try to represent the whole text as well as possible, even when things are working well, we expect some topics may not look interesting - but if you see sequences of words that aren't just boring but actually puzzling (or if you're trying to label topics) it's always important to go look at the documents!\n",
    "\n",
    "With that, we wrap up this brief overview of text curation. One thing we didn't do in this lesson that I'd hoped to was to show that the use of a model to detect issues in data isn't limited to topic models: supervised text classifiers like Naive Bayes classifiers learn weights on how much certain features matter, so one could train a classifier to predict which reviews are fresh versus rotten, then inspect whether some of the words that are considered good indicators of that are indicating a systamtic issue. If you have time to explore more, I recommend checking out [Susan Li's tutorial](https://towardsdatascience.com/multi-class-text-classification-with-scikit-learn-12f1e60e0a9f) for an idea of how to use scikit-learn's multinomial Naive Bayes classifier `MultinomialNB` to do analyses."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "\n",
    "Thank you! For access to the source code of all three lessons, go to [https://github.com/xandaschofield/tapi-text-data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
