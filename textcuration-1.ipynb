{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" src=\"https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/tapi-logo-small.png\" />\n",
    "\n",
    "This notebook free for educational reuse under [Creative Commons CC BY License](https://creativecommons.org/licenses/by/4.0/).\n",
    "\n",
    "Created by [Xanda Schofield](https://www.cs.hmc.edu/~xanda) for the 2022 Text Analysis Pedagogy Institute, with support from the [National Endowment for the Humanities](https://neh.gov), [JSTOR Labs](https://labs.jstor.org/), and [University of Arizona Libraries](https://new.library.arizona.edu/).\n",
    "\n",
    "For questions/comments/improvements, email xanda@cs.hmc.edu.<br />\n",
    "____"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Data Curation 1\n",
    "\n",
    "This is lesson 1 of 3 in the educational series on Text Data Curation. This notebook is intended to introduce the basics of treating text documents as data and how to store and filter those documents. \n",
    "\n",
    "**Audience:** `Learners` / `Researchers`\n",
    "\n",
    "**Use case:** [`How-To`](https://constellate.org/docs/documentation-categories#howtoproblemoriented) \n",
    "\n",
    "**Difficulty:** `Intermediate`\n",
    "This course is open to those with a basic level of proficiency in Python. Taking the Python Basics course the week before is sufficient.\n",
    "\n",
    "**Completion time:** `90 minutes`\n",
    "\n",
    "**Knowledge Required:** \n",
    "```\n",
    "* Python basics (variables, flow control, functions, lists, dictionaries)\n",
    "* How Python libraries work (installation and imports)\n",
    "```\n",
    "\n",
    "**Knowledge Recommended:**\n",
    "```\n",
    "* Basic file operations (open, close, read, write)\n",
    "* How text is stored on computers (encodings, file types)\n",
    "```\n",
    "\n",
    "**Learning Objectives:**\n",
    "After this lesson, learners will be able to:\n",
    "```\n",
    "1. Parse and generate XML, JSON, and CSV files given raw text documents\n",
    "2. Identify when text encodings affect the interpretation of text data\n",
    "3. Use a lexicon to select relevant documents within a text collection\n",
    "4. Use fuzzy matching to remove duplicate items from a collection\n",
    "```\n",
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Python Libraries\n",
    "`List out any libraries used and what they are used for`\n",
    "* [Tesseract](https://tesseract-ocr.github.io/) for performing [optical character recognition](https://docs.constellate.org/key-terms/#ocr).\n",
    "* [Pandas](https://pandas.pydata.org/) for manipulating and cleaning data.\n",
    "* [Pdf2image](https://pdf2image.readthedocs.io/en/latest/) for converting pdf files into image files.\n",
    "\n",
    "## Install Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Libraries ###\n",
    "\n",
    "# Using !pip installs\n",
    "!pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Required Data\n",
    "\n",
    "`List out the data sources, including their formats and a few sentences describing the data. Include a link to the data source description, if possible.`\n",
    "\n",
    "**Data Format:** \n",
    "* plain text (.txt)\n",
    "* delimited files (.csv, .tsv)\n",
    "* structured files (.json, .xml, .html)\n",
    "\n",
    "**Data Source:**\n",
    "* [Spanish Poetry Dataset](https://www.kaggle.com/datasets/andreamorgar/spanish-poetry-dataset): Spanish poem names scraped from [Poemas del Alma](https://www.poemas-del-alma.com/).\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "`This lesson uses XXXX data in XXX format from XXXX source. Additional details about the data used.`\n",
    "\n",
    "## Download Required Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "### Grab files with console `wget` and `mv` ###\n",
    "!wget https://github.com/tesseract-ocr/tessdata/raw/main/eng.traineddata\n",
    "!mv eng.traineddata /usr/share/tesseract-ocr/4.00/tessdata/eng.traineddata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Grab a single file and supply name ###\n",
    "urllib.request.urlretrieve('https://file.address.txt', 'filename.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve multiple files using a list ###\n",
    "\n",
    "download_urls = [\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_01.pdf',\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_02.pdf',\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_03.pdf'\n",
    "]\n",
    "\n",
    "for url in download_urls:\n",
    "    urllib.request.urlretrieve(url, url.rsplit('/', 1)[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Retrieve multiple files using a list ###\n",
    "### With data folder creation using os ###\n",
    "\n",
    "# Files hosted somewhere else (don't store data on GitHub)\n",
    "\n",
    "# Check if a folder exists to hold pdfs. If not, create it.\n",
    "if os.path.exists('sample_pdfs') == False:\n",
    "    os.mkdir('sample_pdfs')\n",
    "\n",
    "# Move into our new directory\n",
    "os.chdir('sample_pdfs')\n",
    "\n",
    "# Download the pdfs into our directory\n",
    "import urllib.request\n",
    "download_urls = [\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_01.pdf',\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_02.pdf',\n",
    "    'https://ithaka-labs.s3.amazonaws.com/static-files/images/tdm/tdmdocs/sample_03.pdf'\n",
    "]\n",
    "\n",
    "for url in download_urls:\n",
    "    urllib.request.urlretrieve(url, url.rsplit('/', 1)[-1])\n",
    "    \n",
    "## Move back out of our directory\n",
    "os.chdir('../')\n",
    "\n",
    "## Success message\n",
    "print('Folder created and pdfs added.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Constellate Example ###\n",
    "\n",
    "# Importing your dataset with a dataset ID\n",
    "import constellate\n",
    "# Pull in the sampled dataset (1500 documents) that matches `dataset_id`\n",
    "# in the form of a gzipped JSON lines file.\n",
    "# The .get_dataset() method downloads the gzipped JSONL file\n",
    "# to the /data folder and returns a string for the file name and location\n",
    "dataset_id = \"02b8c5c7-64bd-efe3-01d8-88c9efe7d17c\"\n",
    "dataset_file = constellate.get_dataset(dataset_id)\n",
    "\n",
    "# To download the full dataset (up to a limit of 25,000 documents),\n",
    "# request it first in the builder environment. See the Constellate Client\n",
    "# documentation at: https://constellate.org/docs/constellate-client\n",
    "# Then use the `constellate.download` method show below.\n",
    "#dataset_file = constellate.download(dataset_id, 'jsonl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "This is the first of three lessons on **text data curation**, aimed for an audience with a little bit of information on how Python works that's interested in embarking on a quest to work with a large collection of text using computational tools. Here, we will look specifically at the ways we store text and collections of documents on computers and tools we can use to filter those larger collections into something usable. The tutorial is targeted at individuals interested in computational text analysis who are acquainted with the basics of programming in Python but are still new to developing models of text or more complex natural language processing tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lesson\n",
    "\n",
    "\n",
    "## When text is data\n",
    "There are lots of ways to gain understanding of texts. We can read the texts themselves closely, read about the history of the texts' subject and of its authors, dig up related or contemporary texts, and grapple with the critical responses others have had to each. Depending on the questions we want to answer or our worldview about textual analysis in general, we might take a mixture of these different strategies together to analyze, answer, and argue on one topic.\n",
    "\n",
    "Computational text analysis provides another set of strategies to do this, with a specific emphasis on what is (or isn't) a pattern across numerous texts. To do this, text collections are fed to computer programs that count, contrast, and correlate events that happen in texts, ranging from the basic frequencies of individual words and phrases to more complex inferences of what events occur for a particular character or what sentiments or moods are prevalent around mentions of a specific theme. Approaches to find these patterns range from direct programming (e.g. writing code in Python or R) to interacting with visual interfaces (like Voyant or Tableau) to options that merge the two (like building an extensive spreadsheet in Excel).\n",
    "\n",
    "In my experience, there's an amazing ecosystem of different tools and tutorials out there to train models, compute statistics, and visualize results around text: it's just a matter of getting the text you care about into the right state to be usable by that system. And that's where **text data curation** comes in.\n",
    "\n",
    "I define **text data** to be a structured format of textual information (that is, sequences of symbols that encode human language) intended for use in some kind of processing and computation. When we treat text as data, we have to enforce a certain degree of uniformity in how this text looks so the processing can be consistent. Most human-generated text collections, however, are not so tidy, no matter where they come from, who collected them, or what journey the text took to become a modern-day record. To succeed in text data analysis, we need to be able to grapple with this non-uniformity, to **curate** what text stays, how to store it, and how to transform it into something uniform.\n",
    "\n",
    "Today, we're going to focus primarily on the first two questions: how to select the documents to keep and what representations are convenient for storing that text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TSVs and a basic filtering task\n",
    "\n",
    "It's important to acknowledge before we embark on this project: the process of text data curation for these applications is not neutral: it's *subjective* and *destructive*. Let's think about a case study to understand how this looks.\n",
    "\n",
    "Suppose I'm interested in studying dominant themes in contemporary Spanish language poetry. To start, I want to find a large collection of these poems. I find out that the website [Poemas del Alma (\"Poems of the Soul\")](https://www.poemas-del-alma.com/) has hundreds of thousands of user-submitted poems from 2009 onwards. I also find an existing script written in Python to scrape the literary poems on the website, which I could adapt to get the user poems as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at the *metadata* of these. This includes the titles, authors, month of publication, and URLs for each poem. I've actually created three different versions of this metadata file: a TSV file, a CSV file, a JSON file, and an XML file. We'll start by loading in the first TSV file. I've added some helper functions for reading and writing TSVs into lists of dictionaries below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def read_tsv_as_dicts(filename):\n",
    "    \"\"\"Load in a TSV, or tab-separated value file, using Python's \n",
    "    built-in library `csv` for parsing fixed delimiter files. Loads\n",
    "    in each row as a dictionary.\"\"\"\n",
    "    # open the file in read mode\n",
    "    with open(filename) as tsv_file:\n",
    "        reader = csv.DictReader(tsv_file, delimiter='\\t')\n",
    "        row_dictionaries = [row for row in reader]\n",
    "    return row_dictionaries\n",
    "\n",
    "def write_tsv_from_dicts(rows, filename):\n",
    "    \"\"\"Given a list of dictionaries with consistent keys, writes\n",
    "    out a tab-separated value file using Python's built-in library\n",
    "    `csv` to interpret the rows.\n",
    "    \"\"\"\n",
    "    # open a file in write mode\n",
    "    with open(filename, 'w') as tsv_file:\n",
    "        # we grab the list of column names from the keys of\n",
    "        # one of the rows\n",
    "        columns = list(rows[0].keys())\n",
    "        writer = csv.DictWriter(tsv_file, columns, delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function gives us `row_dictionaries`, a list of dictionaries that each contain the information of one row. In this case, each row will have the metadata of one poem. Because this is a TSV file, each of the poems has one line in the file, with a **T**ab character between each entry to delimit the different pieces of information into columns. (Because people don't really use tabs in their poem names, this is a pretty safe option to split our text.) We can see the names of the columns by looking at the first 10 lines of the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "url\ttitle\tauthor\tyear\tmonth\tpage\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-36\tHaiku.  Yo soy\t Rafael Merida Cruz-Lascano\t2009\t1\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-49\t\"Poema √âpico  \"\"Tecum Um√°n\"\"\"\t Rafael Merida Cruz-Lascano\t2009\t1\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-56\t-Sorsonete- ‚ÄúLA  LIBERTAD  DE  CRISEIDA‚Äù\t Rafael Merida Cruz-Lascano\t2009\t1\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-58\tRomance nuevo SIRENA CONSENTIDA\t Rafael Merida Cruz-Lascano\t2009\t1\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-78\tVacia por dentro\t sha_nena\t2009\t2\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-79\tSola en la realidad\t sha_nena\t2009\t2\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-88\tEl destino de ser flor.\t Lizelizalde\t2009\t2\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-89\tRecuerdo de Infancia\t Angela\t2009\t2\t0\n",
      "\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-91\tAl amar\t Oscar Raul Quiroz Cortejana\t2009\t2\t0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "with open('poetry_metadata_2009.tsv') as metadata_file:\n",
    "    # print the first ten raw lines of the file\n",
    "    for i in range(10):\n",
    "        print(metadata_file.readline())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this file, we can see the 0th line (remember, Python starts counting at 0) gives us the names of each of the columns, and each of the lines after that is for a specific poem. This sort of file can get loaded into Excel if you want cleanly visible columns, but if we just read it as a plain text file, we can still roughly sort out what items should be present in what order. It's a little easier to read these once we have them loaded in as dictionaries in Python, so let's look at one of those:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-36', 'title': 'Haiku.  Yo soy', 'author': ' Rafael Merida Cruz-Lascano', 'year': '2009', 'month': '1', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-49', 'title': 'Poema √âpico  \"Tecum Um√°n\"', 'author': ' Rafael Merida Cruz-Lascano', 'year': '2009', 'month': '1', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-56', 'title': '-Sorsonete- ‚ÄúLA  LIBERTAD  DE  CRISEIDA‚Äù', 'author': ' Rafael Merida Cruz-Lascano', 'year': '2009', 'month': '1', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-58', 'title': 'Romance nuevo SIRENA CONSENTIDA', 'author': ' Rafael Merida Cruz-Lascano', 'year': '2009', 'month': '1', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-78', 'title': 'Vacia por dentro', 'author': ' sha_nena', 'year': '2009', 'month': '2', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-79', 'title': 'Sola en la realidad', 'author': ' sha_nena', 'year': '2009', 'month': '2', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-88', 'title': 'El destino de ser flor.', 'author': ' Lizelizalde', 'year': '2009', 'month': '2', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-89', 'title': 'Recuerdo de Infancia', 'author': ' Angela', 'year': '2009', 'month': '2', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-91', 'title': 'Al amar', 'author': ' Oscar Raul Quiroz Cortejana', 'year': '2009', 'month': '2', 'page': '0'}\n",
      "{'url': '//www.poemas-del-alma.com/blog/mostrar-poema-98', 'title': 'La niebla ', 'author': ' Nassib A. A.', 'year': '2009', 'month': '2', 'page': '0'}\n"
     ]
    }
   ],
   "source": [
    "# read in the data from a TSV format\n",
    "poetry_metadata = read_tsv_as_dicts('poetry_metadata_2009.tsv')\n",
    "\n",
    "for i in range(10):\n",
    "    print(poetry_metadata[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can guess pretty quickly that this dataset is in chronological order starting from January (month 1) 2009, which only had four poems - three of which are by the same author. That makes sense, since the website may have just been starting up, but does lead us to ask a question: are there trends in the number of poems being added over time? And how distributed across authors are our poems?\n",
    "\n",
    "These are answers we can evaluate using the `Counter` class, which you may have encountered already in Intro to Python. Whether or not you have, the quick version is that it's a special kind of dictionary that is designed to count how many times each unique item shows up in a sequence. We can do this to sort out how many times each author shows up once we've loaded in our data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total authors: 1757\n",
      "245  ANEUDIS PEREZ\n",
      "183  julio oropeza\n",
      "168  FERNANDO CARDONA\n",
      "158  Violeta\n",
      "151  Eddy Gtz\n",
      "148  Jesus Paredes Ortiz\n",
      "138  ivan semilla\n",
      "135  Franklin Sandi\n",
      "133  Sergio Jacobo \"el poeta irreverente\"\n",
      "124  luz\n",
      "109  Antonia Ceada Acevedo\n",
      "103  Ra_Tito\n",
      "98  Geovani\n",
      "98  MODESTOELPOETA1953\n",
      "97  Sorgalim Narud\n",
      "96  Rosa de los vientos\n",
      "94  El de las Rosas\n",
      "91  luna de hielo\n",
      "90  Nano_Veliz\n",
      "87  checovick\n",
      "85  AZULNEFERTARY\n",
      "82  angelab\n",
      "78  Eco del alma\n",
      "78  Cyrene\n",
      "77  Adrian VeMo\n",
      "77  hmoliut\n",
      "72  eowyn\n",
      "71  YoKo\n",
      "70  Roberto Moran\n",
      "68  migreriana\n",
      "67  JESIMAR\n",
      "66  SERGIO FERNANDO\n",
      "64  Faeton\n",
      "64  F√©lix Moreno\n",
      "63  Bendecido7\n",
      "62  H3c70r P3r32\n",
      "62  saly_rosa\n",
      "60  el duende\n",
      "60  William Cerdas Logan\n",
      "58  Rafael Merida Cruz-Lascano\n",
      "58  skyfire\n",
      "56  C.J poeta\n",
      "55  Miguel Angel Ortigoza Garc√≠a\n",
      "52  cbastias\n",
      "50  Alejandro\n",
      "50  KALITA_007\n",
      "49  aby1982\n",
      "48  figueredo jorge\n",
      "47  Lord VanVle\n",
      "47  sagui\n",
      "46  Herrera Andreyna\n",
      "46  shiny\n",
      "45  ELEPE\n",
      "44  LindaSakura\n",
      "44  Josue sz\n",
      "44  maicolmanya\n",
      "43  psy_angelito\n",
      "43  gatoconbotas_58\n",
      "43  Jose de amercal\n",
      "43  princesa de un cuento infinito\n",
      "43  Abel Niquinga Ruiz\n",
      "42  Nataly Echeverri\n",
      "41  magginela\n",
      "40  abiliv\n",
      "39  BrisaMariana\n",
      "39  Jordi *\n",
      "39  Camilo Gait√°n Avila\n",
      "39  Cock\n",
      "39  Amanda Ackermann\n",
      "38  lucybarudi\n",
      "38  SHARNICOBACS\n",
      "38  ahchoi\n",
      "37  Dante C.\n",
      "37  kevin@valencia\n",
      "36  Carlos Fernando\n",
      "35  JOEL ALEJANDRO HERNANDEZ VELAZQUEZ\n",
      "35  luis andres\n",
      "35  victorlibre\n",
      "34  chitto_cat\n",
      "34  DeL MaR\n",
      "34  adrimor_love\n",
      "34  roxy\n",
      "34  Lluvia Tropical\n",
      "34  Iven Marino Mesina\n",
      "33  Francisco Caleros de la Roca\n",
      "33  Julio Cortazar\n",
      "33  carlito77\n",
      "32  darkshadow\n",
      "32  alamo\n",
      "32  DarkPoet\n",
      "31  free_prometeo\n",
      "31  kristi\n",
      "31  jorge canales\n",
      "30  Poetama\n",
      "30  jacinta ceballos\n",
      "30  ALFREDO\n",
      "30  CHARLI\n",
      "30  CAROL ECHEVERRY\n",
      "30  taty merced\n",
      "30  edwar quintanilla\n",
      "30  Aly Mich√≥\n",
      "29  giuseppe de domenico\n",
      "29  JOED MOSI\n",
      "29  AZUL M.L.\n",
      "29  SASI12\n",
      "28  xOrionx\n",
      "28  remita.p\n",
      "28  Caballero de los Versos\n",
      "28  Steve\n",
      "28  KABABC\n",
      "28  reflejo de vida\n",
      "28  mafa_da\n",
      "27  Lidia\n",
      "27  santu_pulposo\n",
      "27  polita\n",
      "27  Rembrandt\n",
      "27  Black Broken Wings\n",
      "27  vampirella22\n",
      "27  ferconejo\n",
      "26  Liliana Almendros\n",
      "26  ede\n",
      "26  Biby 181\n",
      "26  Andrea Valentina\n",
      "26  emmanuel s√®brol\n",
      "26  Mi otra yo\n",
      "25  Lena\n",
      "25  gerardo villalobos\n",
      "25  freedom to the meals\n",
      "25  el_que_no_esta\n",
      "25  XxselenitaxX\n",
      "25  mr.john\n",
      "25  AMANTE SILENCIOSO\n",
      "25  VAGABUNDO\n",
      "25  SerafinGlr\n",
      "24  Ary Vala\n",
      "24  Rosy Martinez\n",
      "24  ale_dieminger\n",
      "24  thelovetoforgive\n",
      "24  shadow_in_the_sky\n",
      "24  Magali Aguilar Solorza\n",
      "24  Jorge C. I.\n",
      "23  gonzalo puga\n",
      "23  natalie valentina\n",
      "23  valentino malatesta\n",
      "23  Fco Peiro\n",
      "22  bblinda\n",
      "22  johlotuc\n",
      "22  pinksky\n",
      "22  Latino\n",
      "22  linda abdul baki\n",
      "21  corazondefuego\n",
      "21  Gabriela Araceli\n",
      "21  Kurt B. Rinze\n",
      "21  Belial Luzbel\n",
      "21  Vey\n",
      "21  Fernando Javier Gamero Oviedo\n",
      "21  RAFO1979\n",
      "21  diego_angel\n",
      "21  luna isis\n",
      "21  flor del nilo\n",
      "21  morocha 2009\n",
      "21  Alexia56\n",
      "21  Eugenio S√°nchez\n",
      "20  Jose Maria Gentile\n",
      "20  venus17\n",
      "20  gatubela34\n",
      "20  Poemas de Pepita Fern√°ndez\n",
      "20  the poetic\n",
      "20  agirllikeme\n",
      "20  Catalina\n",
      "20  0swald0\n",
      "19  Iron Children\n",
      "19  Juan Carlos Luna N√∫√±ez\n",
      "19  lucho pampa\n",
      "19  alma68\n",
      "19  laura09\n",
      "19  Layd\n",
      "19  Blanca Primavera Contreras\n",
      "19  ldeluis\n",
      "18  amme\n",
      "18  gires4\n",
      "18  taniaazul\n",
      "18  Yaretzi\n",
      "18  Kevin Raphael\n",
      "18  Atardecer\n",
      "18  BENjamin\n",
      "18  enlil\n",
      "18  almita\n",
      "18  Lunaluz\n",
      "18  Libra *M*\n",
      "18  mar adentro\n",
      "18  freddy p\n",
      "18  victor febo\n",
      "18  dave5\n",
      "18  Cieroska Porras\n",
      "18  Humberto Mariano\n",
      "17  fernandofedchu\n",
      "17  Mara Acevedo\n",
      "17  MonoFloyd\n",
      "17  ROV\n",
      "17  carlitos8\n",
      "17  pacuns\n",
      "17  vichelito\n",
      "17  Einer Fidel Casta√±o Villamil\n",
      "17  FERABIT\n",
      "17  rafa1\n",
      "17  alexander omar\n",
      "17  Cesar Martinez Miranda\n",
      "17  el poeta perdido\n",
      "17  FrankMx\n",
      "17  BryanGomez\n",
      "16  tu siempre enamorado\n",
      "16  ivanrivera91\n",
      "16  PETER\n",
      "16  elrockerdetuamor\n",
      "16  JhonAlonso\n",
      "16  romeo14\n",
      "16  Oscar Jossiee\n",
      "16  runnerk\n",
      "16  Jean-Paul Saumon\n",
      "16  yael\n",
      "16  aldo henrik\n",
      "16  Oliver Queen\n",
      "16  akinX gayXa\n",
      "16  elio alves\n",
      "16  mary07\n",
      "16  RossanaB.\n",
      "15  Estrella\n",
      "15  Jaime20\n",
      "15  Jason Leon\n",
      "15  Azareel\n",
      "15  crishello\n",
      "15  Lean\n",
      "15  SashoV\n",
      "15  Melucia\n",
      "14  Deko\n",
      "14  BENJAMIN ROMERO\n",
      "14  judith esperanza\n",
      "14  charlie50mas\n",
      "14  Gerson E. A. Arenivar\n",
      "14  annielu\n",
      "14  sonia.erl\n",
      "14  LULU HDZ.\n",
      "14  Elsy Alpire Vaca\n",
      "14  Marcos\n",
      "14  nxo\n",
      "14  Dominatorque\n",
      "14  paula perez sanchez\n",
      "14  Carlos Echavarria\n",
      "14  vanjub\n",
      "14  Luis Alberto Cruz Bolmey\n",
      "13  SILVIO\n",
      "13  MaRiPoSa\n",
      "13  Alfonsina G.\n",
      "13  Danny T\n",
      "13  nancybeatriz\n",
      "13  Luis V√°zquez\n",
      "13  Muzzyblue\n",
      "13  rodwailers\n",
      "13  PAPRIKA\n",
      "13  Lau_22\n",
      "13  kuore\n",
      "13  Manuel Palacios\n",
      "13  cassandra\n",
      "13  silviagarza\n",
      "13  Goldenman\n",
      "13  Pedro Luis Martinez\n",
      "12  Angel ¬°123!\n",
      "12  lobo solitario\n",
      "12  Claudieta\n",
      "12  Djpeter02\n",
      "12  CharlotteWeasley\n",
      "12  Luis Cornelio K.\n",
      "12  eldiego950\n",
      "12  memo1500\n",
      "12  silence dogood\n",
      "12  Un simple poeta\n",
      "12  Komodo\n",
      "12  \n",
      "12  carlosmoreno\n",
      "12  So√±adora\n",
      "12  Diego Somoza\n",
      "12  a. santas\n",
      "12  Txus Di Fellatio\n",
      "12  Johnny Mad Hatter\n",
      "12  ALLAN GARCIA MENDEZ\n",
      "12  vicentebaez\n",
      "12  Idelfonso Buitrago Arango\n",
      "12  DUVIKA\n",
      "12  El Principiante\n",
      "12  Mar√≠a B N√∫√±ez\n",
      "12  connantt\n",
      "12  Naima Andrea\n",
      "12  Carlamor\n",
      "12  francisco garfias\n",
      "12  Humberto Iv√°n Escobar Sayes\n",
      "11  Boa-Gente\n",
      "11  ivanxxv\n",
      "11  Luisg\n",
      "11  julio dominguez\n",
      "11  Alexander Ulianov\n",
      "11  letras_muertas\n",
      "11  GGGJoel\n",
      "11  LiTtle PrInCeS\n",
      "11  l homme en fevrier\n",
      "11  Lewis\n",
      "11  dulceamor\n",
      "11  ekyxzz\n",
      "11  H√©ctor\n",
      "11  Fabian Amaya\n",
      "11  pedro monteza\n",
      "11  CyberFox\n",
      "11  lol-gazan\n",
      "11  aniita\n",
      "11  HenniLopez\n",
      "11  Corazon Errante29\n",
      "11  Everth Aguilar\n",
      "11  Azhar\n",
      "11  Anaros\n",
      "11  Solitario\n",
      "11  el don juan di marco\n",
      "11  AmoritaC\n",
      "11  mardazu\n",
      "11  Vicente Mart√≠n Mart√≠n\n",
      "10  grandote61\n",
      "10  churras\n",
      "10  ellen\n",
      "10  Jose Arher\n",
      "10  lokocach\n",
      "10  Wilkis Santana\n",
      "10  alas de mariposa ‚ô•\n",
      "10  MariaCarolina\n",
      "10  Lum√≠a*\n",
      "10  joshua\n",
      "10  asd\n",
      "10  Gouss\n",
      "10  Luz marina Seneca\n",
      "10  Karen Andrea\n",
      "10  Kaire\n",
      "10  Dexy96\n",
      "10  Erick\n",
      "10  AQUILES PIMIENTO\n",
      "10  Shuchus\n",
      "10  witch poeta\n",
      "10  florvenenosa06\n",
      "10  ‚ô• Princesa de Dios ‚ô•\n",
      "10  cherub\n",
      "10  GCR\n",
      "10  MARYPILI VASQUEZ\n",
      "10  EL JUGUETE\n",
      "10  Beatriz, la que te hace feliz!!!\n",
      "10  japonesita\n",
      "10  Eliette Perez\n",
      "10  Marta Salazar\n",
      "9  Nassib A. A.\n",
      "9  Gepetto Yp\n",
      "9  Evelio Pereira Salgado\n",
      "9  isabel88\n",
      "9  La Poetisa Negra\n",
      "9  princesa83890\n",
      "9  aim√©\n",
      "9  MANTAS MANTAS LAURA\n",
      "9  sophiacooper\n",
      "9  CRISSA\n",
      "9  ErIzZ\n",
      "9  ra√≠ces fuertes y perenes\n",
      "9  Sebastian Torres\n",
      "9  gabiegarcia\n",
      "9  ronnin_muchukunda\n",
      "9  vgvo\n",
      "9  XRebekaX\n",
      "9  maariizh\n",
      "9  daniel cardenas pulgar\n",
      "9  AndreaR.\n",
      "9  lugar\n",
      "9  Cristina24\n",
      "9  MUFFASO\n",
      "9  Rosario Bersabe Montes\n",
      "9  Echeguren\n",
      "9  fantasy day\n",
      "9  Bella\n",
      "9  Lizardo\n",
      "9  athanatos\n",
      "9  ricky123\n",
      "9  maru _ stafe\n",
      "9  unicornioazul\n",
      "9  laynamichel31\n",
      "9  walker\n",
      "9  nerikowski\n",
      "9  Wilfredo Chirinos Figueroa\n",
      "9  Iv√°n V√©lez N√∫√±ez\n",
      "9  RaulAguilera\n",
      "9  Federico Mendo S√°nchez\n",
      "9  monstruilia\n",
      "9  Ivdar Kiunter\n",
      "9  PERCY ROJAS HUANUCO\n",
      "9  deiback\n",
      "8  milijoes\n",
      "8  GIZELL üòç\n",
      "8  mariposaazul\n",
      "8  Alsazzi Terrato\n",
      "8  vincen\n",
      "8  gatetaadhara\n",
      "8  Veronica Amador Merida\n",
      "8  Ivan Guerrero\n",
      "8  Alicia Acevedo Inzunza\n",
      "8  laia\n",
      "8  cirqus\n",
      "8  Rubens\n",
      "8  Laurari V.\n",
      "8  claudio cienfuegos\n",
      "8  Khryzan\n",
      "8  derfischer23\n",
      "8  azzgy\n",
      "8  gabriel_gabriel\n",
      "8  Cande\n",
      "8  MarisMadrid\n",
      "8  Taylor Sanchez\n",
      "8  el angel del amor\n",
      "8  oskar_young\n",
      "8  Frank Carlos\n",
      "8  Saphire\n",
      "8  Rafaga\n",
      "8  Dina Sanchez\n",
      "8  Teddy Jojo\n",
      "8  HidalgoII\n",
      "8  hammy\n",
      "8  Ricardo Nogal\n",
      "8  Janeiro\n",
      "8  loco enamorado\n",
      "8  DarKraD\n",
      "8  carlos_panella\n",
      "8  gustavo chilito\n",
      "8  gaury\n",
      "8  Hugo Blair M.\n",
      "8  INCOMPRENDIDO22\n",
      "8  sirpoeta\n",
      "8  kullo\n",
      "8  jeremi joss\n",
      "8  Lotus Flower\n",
      "8  El Poeta Diurno\n",
      "8  chevere\n",
      "8  Ami\n",
      "8  ZORE\n",
      "8  gilamor7782\n",
      "8  rosa cecilia\n",
      "8  il poeta della notte\n",
      "8  norma de juanmy\n",
      "7  maeoteo\n",
      "7  Gerardo\n",
      "7  elbinsi\n",
      "7  alexa o ali\n",
      "7  kida\n",
      "7  walberto campos\n",
      "7  Irmangeles\n",
      "7  kororita\n",
      "7  LADY HUAMAN MANTARI\n",
      "7  leoncito_93\n",
      "7  Genciana.\n",
      "7  Frances Villa\n",
      "7  Shekina\n",
      "7  FireScorpion_17\n",
      "7  la chu\n",
      "7  mvictor\n",
      "7  Enri\n",
      "7  gilga\n",
      "7  sednalia\n",
      "7  FeRnAnDiiTha\n",
      "7  Barb\n",
      "7  Horacio P√°ramo\n",
      "7  Rolando Coronel\n",
      "7  Eduardo Angeles De Rivero\n",
      "7  and\n",
      "7  SapiensA\n",
      "7  JC. ROMAN\n",
      "7  Yacita\n",
      "7  MujerBuho\n",
      "7  @javi_anticlon\n",
      "7  Wagner Campos\n",
      "7  hanni19\n",
      "7  Leonardo Ramos\n",
      "7  quebonitaeslamar\n",
      "7  Carolina\n",
      "7  marcelito\n",
      "7  Adonis\n",
      "7  ysis\n",
      "7  Fantasma\n",
      "7  D.J.\n",
      "7  pablocp\n",
      "7  diantre\n",
      "7  enrique7376\n",
      "7  peregrinodellago\n",
      "7  √Åguila77\n",
      "7  luz arely nava parra\n",
      "7  Pablo Karusso\n",
      "6  chucho\n",
      "6  Dorril\n",
      "6  Flor de amor\n",
      "6  andresladino\n",
      "6  Mary Arias\n",
      "6  Quique-Fantasy\n",
      "6  lidu86\n",
      "6  Manute\n",
      "6  taka\n",
      "6  cangasramon\n",
      "6  el_peluso\n",
      "6  Mariposa marina\n",
      "6  cipres1957\n",
      "6  Eli-Momo\n",
      "6  Olivera Alonso Magoa\n",
      "6  ejup\n",
      "6  Alejandro Alberti Wolfart\n",
      "6  JUAN DEL ALMA\n",
      "6  Gothik_Leii\n",
      "6  christian aranda\n",
      "6  Stefania Valle Fern√°ndez\n",
      "6  kidagakash nedak\n",
      "6  eMoESTERstyle\n",
      "6  Isaac Eduardo\n",
      "6  Poetiisa\n",
      "6  Loren Sanchez\n",
      "6  laura06\n",
      "6  agnusdark\n",
      "6  rosa nocturna\n",
      "6  vane_mili\n",
      "6  Klpf\n",
      "6  shiine\n",
      "6  dimitrinski\n",
      "6  Pekorasmarrita\n",
      "6  madrid\n",
      "6  chocmanonline\n",
      "6  malu por siempre\n",
      "6  rousyab\n",
      "6  principedechocolate\n",
      "6  allen snager\n",
      "6  Danco\n",
      "6  --- Kiks ---\n",
      "6  Jose Sotero\n",
      "6  Lucy Shines\n",
      "6  Carlos Smyrlock\n",
      "6  erdauren\n",
      "6  dark_angel_dead\n",
      "6  lau_ac\n",
      "6  Rena\n",
      "6  CitizenGhola\n",
      "6  sofi rock\n",
      "6  Mandy Isabella\n",
      "6  Angelica\n",
      "6  pala9306\n",
      "6  david valencia tobon\n",
      "6  Alebrije\n",
      "6  C√©sar Crist√≥bal\n",
      "6  alfredo perales\n",
      "6  Claudia Presenza\n",
      "6  Edison Agudelo\n",
      "6  siemprefiel\n",
      "6  MARIA ANTONIETA\n",
      "6  LINEARBAL\n",
      "6  idalia1609\n",
      "6  MAXIMO BENITES\n",
      "6  alma\n",
      "6  5o.Reyes\n",
      "6  zhio-montiel\n",
      "6  angeluxx\n",
      "6  poetics\n",
      "6  jorgam\n",
      "6  Javiereal\n",
      "6  Fredi17\n",
      "5  sha_nena\n",
      "5  blank\n",
      "5  --mary_a--\n",
      "5  Rodr4\n",
      "5  Bart el caballero enamorado\n",
      "5  tony1\n",
      "5  Eremita\n",
      "5  Narcizo\n",
      "5  dierock\n",
      "5  Alfredo Robles\n",
      "5  steven masis sanchez\n",
      "5  Jude\n",
      "5  Yolima Socha\n",
      "5  trisol\n",
      "5  carlos_lobo7\n",
      "5  esteban de la poe\n",
      "5  elizabethespirillapumaccari\n",
      "5  araceli leon\n",
      "5  Giamalyn\n",
      "5  daniel9\n",
      "5  javier marin\n",
      "5  charlykpo\n",
      "5  Ledita\n",
      "5  ang\n",
      "5  gatita concentida\n",
      "5  Venus\n",
      "5  Marianela\n",
      "5  camely\n",
      "5  Alberto Esquivel\n",
      "5  RedRose\n",
      "5  esmeralda elizabeth\n",
      "5  Octavio\n",
      "5  Fernando R\n",
      "5  lehtra50\n",
      "5  lal_marcos\n",
      "5  Gregory\n",
      "5  kidomaru\n",
      "5  magdyyes\n",
      "5  yusty\n",
      "5  Ecina\n",
      "5  gisselle\n",
      "5  elmerla1\n",
      "5  Rabel\n",
      "5  rsolano\n",
      "5  y@shi\n",
      "5  Pelayo\n",
      "5  rosyglez\n",
      "5  yihu\n",
      "5  Rizabell Laracuente\n",
      "5  poetasola\n",
      "5  Sandra Grajales\n",
      "5  Jhoinis Gil Rodelo\n",
      "5  dulce_poettizza\n",
      "5  JaZz\n",
      "5  h24plus\n",
      "5  JeronimoCesar\n",
      "5  claloka\n",
      "5  ksanova\n",
      "5  FERNANDO CAMA\n",
      "5  vikki\n",
      "5  alma de angel\n",
      "5  johan99\n",
      "5  Celina Vautier\n",
      "5  Chik De HumO\n",
      "5  oscar geancarlos\n",
      "5  melros\n",
      "5  temerario\n",
      "5  mila12\n",
      "5  Aritza\n",
      "5  Sad_Spektro\n",
      "5  kames\n",
      "5  lovocam\n",
      "5  Genaro A. Cancino\n",
      "5  dark princess\n",
      "5  moira\n",
      "5  ojitos bonitos\n",
      "5  Nahuel4rtaud\n",
      "5  PaoChan\n",
      "5  Dedos_magicos\n",
      "5  Beluu18\n",
      "5  alex morrison\n",
      "5  yuyipsu\n",
      "5  elrincondeeloisa\n",
      "5  Rosicela Garcia\n",
      "5  kiko Bravo\n",
      "5  Patricia Palma\n",
      "5  fredy_poeta\n",
      "5  neuvelis\n",
      "5  Baraka\n",
      "4  Segrob\n",
      "4  Edwardv8\n",
      "4  lexmi\n",
      "4  NIKOPOL\n",
      "4  Johnnis\n",
      "4  antonio\n",
      "4  daygo\n",
      "4  Molina\n",
      "4  j_e_d_a_\n",
      "4  valita86\n",
      "4  nena_peque\n",
      "4  Floren Solaz\n",
      "4  joel josseph Bustamante Bartolo\n",
      "4  Agricultor\n",
      "4  ernesto_25\n",
      "4  tristeromancero\n",
      "4  Tamsley\n",
      "4  L√≠dice Robinson\n",
      "4  ∆∏ÃµÃ°”úÃµÃ®ÃÑ∆∑ ‚ô•@ngel de kristal‚ô• ∆∏ÃµÃ°”úÃµÃ®ÃÑ∆∑\n",
      "4  Sirenita\n",
      "4  pequebu\n",
      "4  KayS\n",
      "4  ana phelps\n",
      "4  albrecht\n",
      "4  katty\n",
      "4  angel_nena17\n",
      "4  Salma\n",
      "4  Nelson Israel\n",
      "4  :: LEAH LAND ::\n",
      "4  Alejandre Alves\n",
      "4  carlesdrac\n",
      "4  daffy12\n",
      "4  broval\n",
      "4  outsider\n",
      "4  Ximee10\n",
      "4  Lukateli\n",
      "4  Mimocancel\n",
      "4  juankis\n",
      "4  Karlatissa\n",
      "4  fabyfabyfaby\n",
      "4  Adrian David\n",
      "4  Megara\n",
      "4  Emily Carpio Montoya\n",
      "4  mafe\n",
      "4  aleejandraa\n",
      "4  milena\n",
      "4  Peter Bustamante\n",
      "4  carolinabrdv\n",
      "4  M Antonio\n",
      "4  Magda777\n",
      "4  jhonb.boy\n",
      "4  guillermo andres\n",
      "4  mimo19\n",
      "4  estrellita2009\n",
      "4  roeugui2009\n",
      "4  Kelly O.\n",
      "4  leonardo alexis\n",
      "4  ratoncita\n",
      "4  el filosofo\n",
      "4  XOEL\n",
      "4  _GmmG_\n",
      "4  Jason\n",
      "4  yustonnils\n",
      "4  Mayte Salguero\n",
      "4  poeta_cautivado\n",
      "4  liztrock\n",
      "4  loveme\n",
      "4  Carlisle KM\n",
      "4  Camilox\n",
      "4  Carla eliana\n",
      "4  conjuronocturno\n",
      "4  vanessa varela\n",
      "4  betterman\n",
      "4  Alejandro Casta√±o Naranjo\n",
      "4  Henyer\n",
      "4  wisavi\n",
      "4  mikiaven\n",
      "4  Juan Antonio Riquelme\n",
      "4  arcadio rivas\n",
      "4  MujerDeArena\n",
      "4  jasonthegame\n",
      "4  tangoromeo3\n",
      "4  magdae\n",
      "4  Nalalove\n",
      "4  Joan_A_B\n",
      "4  Pavlov\n",
      "4  Angy Gonzalez\n",
      "4  carliebe\n",
      "4  AmY13\n",
      "4  Ricardo BV.\n",
      "4  cevergarar@hotmail.com\n",
      "4  steven m.\n",
      "4  esperanzadelmar\n",
      "4  navidad_azul\n",
      "4  JHON STEVE CANSAYA CARRION\n",
      "4  leo5584\n",
      "4  Leidycgt\n",
      "4  Jorge A. Porras Teppa\n",
      "4  espitt\n",
      "4  Diego P√©rez\n",
      "4  daruto\n",
      "4  en la oscuridad hermosa\n",
      "4  ramger65\n",
      "4  EliGu\n",
      "4  P.R ROMANTICISTA\n",
      "4  krades natanoj\n",
      "4  Maria\n",
      "4  tony soto flores\n",
      "4  erck veloz...\n",
      "4  Blk Dante\n",
      "4  Mona Lisa\n",
      "4  tcmedina\n",
      "4  Don Juan 00\n",
      "4  Nelly Altuna\n",
      "4  Amy Mole\n",
      "4  So√ëaDoRa\n",
      "4  tintan35\n",
      "4  oxwell L-bu\n",
      "4  celsofernandez\n",
      "3  Xanta\n",
      "3  aannie\n",
      "3  gmocaicedo\n",
      "3  mayu\n",
      "3  nericia\n",
      "3  raulherrera\n",
      "3  johana_arm\n",
      "3  Develynn\n",
      "3  Ricardo PH\n",
      "3  Osfer21\n",
      "3  titi\n",
      "3  sTa_Z\n",
      "3  noelia\n",
      "3  Horacio\n",
      "3  SHOKY\n",
      "3  Mal20\n",
      "3  enamorador\n",
      "3  carmen medina mtz\n",
      "3  sandra17\n",
      "3  albetty\n",
      "3  Sir Happy\n",
      "3  ZtreiiitainzaneMDFKZ\n",
      "3  Isabel Guadalupe Duran Santiago\n",
      "3  Vagolord\n",
      "3  GENESIS ESTIFFANY\n",
      "3  Gux\n",
      "3  evans\n",
      "3  Fernando-Jacubi\n",
      "3  Rigoberto\n",
      "3  jorda_catus\n",
      "3  ALEJANDRO DE LOERA GARCIA\n",
      "3  Papillon en blue\n",
      "3  Judy\n",
      "3  equs\n",
      "3  shofi\n",
      "3  Gitanjelee\n",
      "3  lapoke\n",
      "3  Diana S.\n",
      "3  Pucho\n",
      "3  MattSymbiotic\n",
      "3  marcecrash\n",
      "3  EryelleRingo\n",
      "3  NINES\n",
      "3  labinia\n",
      "3  caperucita roja\n",
      "3  ULISES ZARAZUA\n",
      "3  LinaR4\n",
      "3  antonio rios navarrete\n",
      "3  ArteDeAmar\n",
      "3  Tamara Lobiz√≥n\n",
      "3  Erick SSM\n",
      "3  unaper\n",
      "3  ARIOSTO\n",
      "3  Pablo.Milos\n",
      "3  calvo_inlove\n",
      "3  florenciadf\n",
      "3  pagliari\n",
      "3  ABB\n",
      "3  Veruska\n",
      "3  myrna\n",
      "3  dicaro\n",
      "3  nike\n",
      "3  nightowl\n",
      "3  hernan jose\n",
      "3  Deathly Snake\n",
      "3  maikol laxness\n",
      "3  belkis dennison\n",
      "3  some\n",
      "3  Daniel Mercader\n",
      "3  Adele\n",
      "3  Stebe\n",
      "3  Addis\n",
      "3  nin3\n",
      "3  Andres_\n",
      "3  Dulce_veneno\n",
      "3  joester9\n",
      "3  maria nievas\n",
      "3  Luis Gonzalez\n",
      "3  Milena Palmer\n",
      "3  luis.lopez\n",
      "3  Nikol Campbell\n",
      "3  yessy27\n",
      "3  Eduardo Vieira\n",
      "3  Cesar G\n",
      "3  anita_bele\n",
      "3  rafael romero\n",
      "3  anirehka\n",
      "3  Mactre\n",
      "3  larissa Villacorta\n",
      "3  polucion7\n",
      "3  lutari\n",
      "3  geyzu\n",
      "3  carolam12\n",
      "3  francoyejas\n",
      "3  jesus_marquez\n",
      "3  Ronald Reinford Green Jr.\n",
      "3  GOGO\n",
      "3  karenx28\n",
      "3  toto\n",
      "3  HUARINITA\n",
      "3  JunnLenn\n",
      "3  celiniux\n",
      "3  Bett\n",
      "3  indeedinlove\n",
      "3  Mochuelo\n",
      "3  ragal\n",
      "3  John John\n",
      "3  lisbeth22\n",
      "3  apellan87\n",
      "3  Felicity\n",
      "3  eka1\n",
      "3  xanaina\n",
      "3  Clase98\n",
      "3  poetacrazy\n",
      "3  Abel de Miranda\n",
      "3  Camilo Ernesto\n",
      "3  karlaalina\n",
      "3  yami_la_cangri11\n",
      "3  gabbypri\n",
      "3  Angelo\n",
      "3  Alessa\n",
      "3  julio enrique\n",
      "3  abiflor\n",
      "3  chica_evil\n",
      "3  franbasset\n",
      "3  D. A. Ruiz\n",
      "3  URSULA\n",
      "3  seb4s\n",
      "3  crichi14\n",
      "3  Ment-Enferma\n",
      "3  rambal\n",
      "3  Byron072\n",
      "3  Victoria Vladimir\n",
      "3  John Daniel\n",
      "3  Javier Nieves 'Pajarillo'\n",
      "3  Midnight\n",
      "3  lisemelino\n",
      "3  Alcocer\n",
      "3  valentina cuellar\n",
      "3  Kico Blanco\n",
      "3  fynn\n",
      "3  Eleidy Montiel\n",
      "3  Javi16\n",
      "3  Piere\n",
      "3  Jhonatan Ever\n",
      "3  Alvdan\n",
      "3  Enamorado de Lupita\n",
      "3  luis antonio\n",
      "3  josemi\n",
      "3  claudikiki\n",
      "3  Magda Castillo\n",
      "3  robert marbre\n",
      "2  Angela\n",
      "2  Oscar Raul Quiroz Cortejana\n",
      "2  angievi\n",
      "2  Elmer Cortez\n",
      "2  Manfred\n",
      "2  brenda\n",
      "2  Costantino\n",
      "2  chelo18\n",
      "2  naranjopro\n",
      "2  DANIEL\n",
      "2  Abel\n",
      "2  German Parrado Vera\n",
      "2  martha elena\n",
      "2  desastre\n",
      "2  caranco\n",
      "2  O. E. C. A.\n",
      "2  gabrielitaayala\n",
      "2  bamaalmi\n",
      "2  rosasauco@hotmail.com\n",
      "2  mariny\n",
      "2  Janina Gabri\n",
      "2  Lau\n",
      "2  Marina Paredes Llinares\n",
      "2  zdenka\n",
      "2  Sulem\n",
      "2  Mauricio\n",
      "2  samux\n",
      "2  Pintoralgre\n",
      "2  Marisela\n",
      "2  Natalia Aquino\n",
      "2  gabryelitaz\n",
      "2  Ferrer\n",
      "2  poltergeist\n",
      "2  maru\n",
      "2  misar18\n",
      "2  espectro\n",
      "2  Karenina\n",
      "2  xion\n",
      "2  Josemartin\n",
      "2  sella\n",
      "2  Rikarudo-kun\n",
      "2  la guera\n",
      "2  clavelestristes\n",
      "2  naomi_94\n",
      "2  efrayn\n",
      "2  tasl\n",
      "2  Sarah Valentina\n",
      "2  Pedro Aros Castro\n",
      "2  Lionel Lima\n",
      "2  ALC\n",
      "2  amante de abday\n",
      "2  fridasp\n",
      "2  LIGIA ALTAMAR\n",
      "2  Ivan Sanetti\n",
      "2  Ali Jose\n",
      "2  Zulma\n",
      "2  La\n",
      "2  daniel.ccaldas\n",
      "2  hitokiriarias\n",
      "2  carpediem\n",
      "2  wicttor\n",
      "2  Shellinlove\n",
      "2  Malegria\n",
      "2  mustang\n",
      "2  V\n",
      "2  J. Alberto A.\n",
      "2  nikke\n",
      "2  utopica\n",
      "2  story_teller\n",
      "2  Patricia Elena VILAS\n",
      "2  oliveira\n",
      "2  poesia_dulce\n",
      "2  CARLOS GUILLERMO ESPINOZA LIZANA\n",
      "2  evaluna2002\n",
      "2  sven\n",
      "2  UchihaItachi\n",
      "2  PatriciaMonica\n",
      "2  ELENA ANGELES\n",
      "2  andy fontes\n",
      "2  angelnormix\n",
      "2  TATIANA ROBAYO\n",
      "2  baladasmp3\n",
      "2  yuridia villares\n",
      "2  laureado20\n",
      "2  aventura\n",
      "2  Oscuro sentir\n",
      "2  Astaroth DiMort\n",
      "2  Ilye\n",
      "2  jmpf07\n",
      "2  Laura Arroyo\n",
      "2  chipileta\n",
      "2  Diana\n",
      "2  Yo\n",
      "2  dany romero\n",
      "2  dave L G\n",
      "2  Cristina\n",
      "2  princesa_de_la_dulce_pena\n",
      "2  lagrimas de cristal\n",
      "2  laurirasmus\n",
      "2  elvira.ordonez@yahoo.es\n",
      "2  black_jockers\n",
      "2  4l70mz0\n",
      "2  mitad_demonio_666\n",
      "2  roxiris28\n",
      "2  karen villa\n",
      "2  Humbert Humbert\n",
      "2  mujer encantada\n",
      "2  pihoqahiak\n",
      "2  Javier\n",
      "2  asmer22\n",
      "2  lunaNera\n",
      "2  kazador\n",
      "2  jany stefy\n",
      "2  renata\n",
      "2  JesusGol\n",
      "2  Lirela\n",
      "2  lizbello\n",
      "2  andrea n\n",
      "2  SOLITARIO-666\n",
      "2  LPGaeta\n",
      "2  andres_matiaz\n",
      "2  Raskolnikov\n",
      "2  pgusber\n",
      "2  angela sanson\n",
      "2  x_monnie\n",
      "2  Guru Danilo\n",
      "2  pegrias\n",
      "2  ternuraa71\n",
      "2  anmary\n",
      "2  elbabypoet\n",
      "2  chicalenda\n",
      "2  pebelsneruda\n",
      "2  directo700\n",
      "2  morochiia\n",
      "2  Adrii\n",
      "2  buu707\n",
      "2  dorisnais\n",
      "2  PABLO DURAND\n",
      "2  Petite Patty\n",
      "2  FaNaTiCa_De_tiII\n",
      "2  rafaelCOSME\n",
      "2  El poeta Manya de desem Leo el capo\n",
      "2  ahriell\n",
      "2  EPDN\n",
      "2  Aliariadna\n",
      "2  irving rodriguez\n",
      "2  bt.\n",
      "2  jhosimar\n",
      "2  TPX 011\n",
      "2  AnDrEsRuBeN\n",
      "2  gaby279\n",
      "2  Justine Brice\n",
      "2  lusemo\n",
      "2  aguaruna\n",
      "2  TintadeOroo\n",
      "2  ketzai\n",
      "2  melinacalisaya\n",
      "2  yeshenia\n",
      "2  princesitaw enamorada\n",
      "2  marina\n",
      "2  dorachiarle\n",
      "2  alba\n",
      "2  stephanie19\n",
      "2  alma1426\n",
      "2  jose gonzalez\n",
      "2  iMer\n",
      "2  Remle\n",
      "2  SORAYA MORALES\n",
      "2  kroketa_90\n",
      "2  angel msanz\n",
      "2  nubesita\n",
      "2  mutans83\n",
      "2  alejchu\n",
      "2  dennissalazar\n",
      "2  PLASIDO NELLELY\n",
      "2  no.ce.reyo\n",
      "2  IRWIN\n",
      "2  azile\n",
      "2  95NORTE\n",
      "2  nube_viajera\n",
      "2  MAYOCLBE\n",
      "2  Mar M\n",
      "2  Marcos_capo\n",
      "2  bennypanduro\n",
      "2  AjAraujo\n",
      "2  yoly\n",
      "2  chispaz0\n",
      "2  mejanlop\n",
      "2  jose luciano\n",
      "2  yacoa\n",
      "2  soledad3705\n",
      "2  Deliter\n",
      "2  marcela123456\n",
      "2  Ricardo Avitia\n",
      "2  THE RISE OF DREAMING\n",
      "2  castellano_06\n",
      "2  tornado\n",
      "2  marelia\n",
      "2  RONALD MALLCO\n",
      "2  jose rincon\n",
      "2  milaxx\n",
      "2  laprincesadelcuento\n",
      "2  Panchobalsa\n",
      "2  Ibtissam\n",
      "2  crispeta\n",
      "2  dicava\n",
      "2  chaparra_09\n",
      "2  eduaralex\n",
      "2  merchanos\n",
      "2  danytza00\n",
      "2  pokijontas\n",
      "2  qnito\n",
      "2  robertolaplata\n",
      "2  Tadpole de amor\n",
      "2  cardavid\n",
      "2  fhexer\n",
      "2  J.R. Luna\n",
      "2  Kanwak\n",
      "2  mela...\n",
      "2  said\n",
      "2  pelitos\n",
      "2  Yolanda Melo Daza\n",
      "2  Ma. de Lourdes Cepeda-Correa\n",
      "2  Fabio Mauricio Gutierrez\n",
      "2  meilinmorales\n",
      "2  Poeta triste22\n",
      "2  el dante\n",
      "2  luis mako one\n",
      "2  geny05\n",
      "2  hijo de las sombras\n",
      "2  jacquelinezlatarp\n",
      "2  alizee\n",
      "2  Mikun\n",
      "2  laopatico\n",
      "2  elviramadigan\n",
      "2  Halcon\n",
      "2  _GERALDINE_\n",
      "2  R.A.L.\n",
      "2  HEREDIA\n",
      "2  tara\n",
      "2  mirta noemi esteves\n",
      "2  azul\n",
      "2  Milos J. Comall y Vazz\n",
      "2  mmmyd\n",
      "2  Nelson Serrano\n",
      "2  karen micaela odo\n",
      "2  poetax666\n",
      "2  oasis\n",
      "2  felipe_barrera\n",
      "2  mirada_al_alba\n",
      "2  Lar\n",
      "2  Sofia Moya\n",
      "2  kety\n",
      "2  kymberly\n",
      "2  principe_deyvi\n",
      "2  Bertha Martinez de Anderson\n",
      "2  phillip\n",
      "2  maria antonia santamaria\n",
      "2  ADRIANO\n",
      "2  Cabradeacero\n",
      "2  GOTICA_X0\n",
      "2  jojamaca\n",
      "2  Ram_16\n",
      "2  darien_dear\n",
      "2  090984\n",
      "2  Villuzza\n",
      "2  j e s s\n",
      "2  Felipe...\n",
      "2  Ballety\n",
      "2  raul gandara a\n",
      "2  LIA\n",
      "2  GITANA-KARY\n",
      "2  thesantiago\n",
      "2  Romanet Paulina Figueroa Vergara\n",
      "2  Nolerdorf\n",
      "2  Nizamettin Esen Haymanali\n",
      "2  Lagrima-de-sangre\n",
      "2  YOLITA\n",
      "2  fernando\n",
      "2  Amira\n",
      "2  MARINA COLTON\n",
      "2  enirehka\n",
      "2  Humilde poetisa\n",
      "2  valomau\n",
      "1  Lizelizalde\n",
      "1  palabracaidista\n",
      "1  CORAZONLINDO\n",
      "1  cristian023\n",
      "1  keli\n",
      "1  Randy\n",
      "1  Luna\n",
      "1  Kotty\n",
      "1  fernanda\n",
      "1  Hechicera\n",
      "1  pablomor\n",
      "1  caragonr\n",
      "1  geraldine Aguilar\n",
      "1  alitox_el_poeta12\n",
      "1  prisma\n",
      "1  weyner\n",
      "1  davidlinch\n",
      "1  carlos eduardo\n",
      "1  ppmanvivalavida1001\n",
      "1  elfopoeta\n",
      "1  Luis Sergio\n",
      "1  isabelita\n",
      "1  Galv√°n Barqu√≠n Ricardo\n",
      "1  ely_chobits\n",
      "1  josh_gt\n",
      "1  steven\n",
      "1  Leila\n",
      "1  berdocuga\n",
      "1  Marines\n",
      "1  leon hormazabal\n",
      "1  Nachito\n",
      "1  amiguitodenina\n",
      "1  nereida\n",
      "1  Herbert Rdz\n",
      "1  monika ramirez\n",
      "1  Salvador Pliego\n",
      "1  Nely\n",
      "1  Dune\n",
      "1  jose alberto\n",
      "1  rolong\n",
      "1  roman\n",
      "1  Saray\n",
      "1  jorge luis\n",
      "1  Ra√∫l\n",
      "1  belem\n",
      "1  ANA MAR√çA MANCEDA\n",
      "1  kewyn7\n",
      "1  megg\n",
      "1  ayelen\n",
      "1  brendayupid\n",
      "1  onaplast\n",
      "1  jdelafuente\n",
      "1  Taly\n",
      "1  Pedro La Cruz\n",
      "1  Sofia Agostina\n",
      "1  Maria Victoria\n",
      "1  luca\n",
      "1  Fernando Esmoris\n",
      "1  Pedro Verlaine\n",
      "1  Monje Mont\n",
      "1  Juan931109\n",
      "1  alfonso\n",
      "1  momo\n",
      "1  AMRAAM\n",
      "1  DariYO\n",
      "1  seikasdamor\n",
      "1  lapacha\n",
      "1  MarySolPR\n",
      "1  lizita\n",
      "1  Annyyy\n",
      "1  slam880\n",
      "1  Diana Gaviria\n",
      "1  Doris\n",
      "1  agy_3000\n",
      "1  wrichard\n",
      "1  SmilingChibi\n",
      "1  lady_evans...\n",
      "1  REBECAJP\n",
      "1  wanda0412\n",
      "1  ella esta sola\n",
      "1  galahad garrido\n",
      "1  diana_acr\n",
      "1  victor a.meza\n",
      "1  ANA YUBI\n",
      "1  Miquel Angel\n",
      "1  jesusaiza\n",
      "1  blackheart79\n",
      "1  paol\n",
      "1  juan alberto rivera gallego\n",
      "1  lion\n",
      "1  lokita de amor\n",
      "1  cali\n",
      "1  mlperegrino\n",
      "1  bowhen\n",
      "1  ronal enrique\n",
      "1  caminador\n",
      "1  nuskao\n",
      "1  pinkprinczZ de Dios\n",
      "1  salinas\n",
      "1  Ania\n",
      "1  EL ISMAEL\n",
      "1  katherin armas\n",
      "1  Le Chien Andalou\n",
      "1  mmmm\n",
      "1  cinthia130492\n",
      "1  villamilsoriano\n",
      "1  Chicolatino\n",
      "1  ALFONSOMENDEL\n",
      "1  - vic -\n",
      "1  svanegas\n",
      "1  annalui\n",
      "1  jota\n",
      "1  aldoamadeo\n",
      "1  blu2109\n",
      "1  _Silvana_\n",
      "1  Juan Luis\n",
      "1  enslaved\n",
      "1  esdraz\n",
      "1  maribel\n",
      "1  notekivokesfroggy\n",
      "1  thalina\n",
      "1  marialuisaa\n",
      "1  enteleque\n",
      "1  Didi\n",
      "1  Gercy\n",
      "1  ffiqui\n",
      "1  Rosytere\n",
      "1  JuanManzo\n",
      "1  Elena Cortez\n",
      "1  TCL\n",
      "1  argantonio\n",
      "1  alfana\n",
      "1  Eduardo0505\n",
      "1  Ps\n",
      "1  juancdv\n",
      "1  Libesch\n",
      "1  TRES / MARKO\n",
      "1  Clarissa\n",
      "1  SEPC\n",
      "1  irfe7\n",
      "1  mateox001\n",
      "1  dragon rojo\n",
      "1  Joven Poeta\n",
      "1  EdG96\n",
      "1  Vevis\n",
      "1  camilo-botero\n",
      "1  marsebas\n",
      "1  Moo\n",
      "1  cralia\n",
      "1  Betsabe C.\n",
      "1  Hsc_Carlos\n",
      "1  Polete\n",
      "1  gabrielavipe\n",
      "1  marcelita paz\n",
      "1  patetiicooo\n",
      "1  corazondelator02\n",
      "1  tufieladmirador\n",
      "1  cynthiacape\n",
      "1  karlunsco26\n",
      "1  jorge enrique lopez\n",
      "1  ciclonauta\n",
      "1  ZeroxYuuki\n",
      "1  Alze\n",
      "1  HECTOR QUEVEDO\n",
      "1  Picanacho\n",
      "1  yuselmi\n",
      "1  poemasro\n",
      "1  tila del carmen guillermo yedra\n",
      "1  SILVANA ROSAURA C.\n",
      "1  D_dark\n",
      "1  Kana-chan\n",
      "1  KaThY-zTar\n",
      "1  JOHNNY SAID\n",
      "1  Lauryta\n",
      "1  max junior\n",
      "1  Diego Lithsun\n",
      "1  trovador\n",
      "1  hit_fix\n",
      "1  atilita\n",
      "1  Madelinhsm\n",
      "1  andresypaola\n",
      "1  Gabriela Benites\n",
      "1  nata\n",
      "1  ever gaona quevedo\n",
      "1  archivaldo\n",
      "1  Inti\n",
      "1  saudadeazul\n",
      "1  Henry Chavez\n",
      "1  skaterfrancisco\n",
      "1  zorsi\n",
      "1  matilde ortu√±o\n",
      "1  Carmen Marisa\n",
      "1  pimpolla97\n",
      "1  abbi Mc donal\n",
      "1  Blanca Correa\n",
      "1  InoHuChoNs\n",
      "1  milithaxx\n",
      "1  naybif\n",
      "1  Nohelysa\n",
      "1  lavedomi\n",
      "1  winner98\n",
      "1  Lucia EZ\n",
      "1  inframunda\n",
      "1  lilyrocha\n",
      "1  oscar andres\n",
      "1  marc inoa\n",
      "1  Cometa Rojo\n",
      "1  J Manoel\n",
      "1  luz_de_luna\n",
      "1  Lalislao\n",
      "1  Jorge Aris\n",
      "1  Josue Vargas\n",
      "1  afrikm\n",
      "1  jhakson1\n",
      "1  kena94\n",
      "1  danielNthemetalhead\n",
      "1  SLASH-X\n",
      "1  Sirenit@\n",
      "1  krn\n",
      "1  Abril2504\n",
      "1  pepeargento\n",
      "1  Prometeo_sevilla\n",
      "1  Pedro_elduende\n",
      "1  Rose Mary Garcia Pereira\n",
      "1  CwestO\n",
      "1  eduxaso\n",
      "1  alexis77\n",
      "1  ary\n",
      "1  grvyn1\n",
      "1  Mil@gr0zz\n",
      "1  osojocoso\n",
      "1  Leonardo A.\n",
      "1  Elmast\n",
      "1  ajoporro\n",
      "1  isi\n",
      "1  erdur\n",
      "1  raulrobles\n",
      "1  cristo26\n",
      "1  dafne.romantica\n",
      "1  JOHNYOLY\n",
      "1  sinclair\n",
      "1  Clavel\n",
      "1  Pichy\n",
      "1  a4c28\n",
      "1  Tears\n",
      "1  Wesdot\n",
      "1  EMILYBALMA\n",
      "1  o_cerna\n",
      "1  Christian Iv√°n\n",
      "1  euperth\n",
      "1  Leona\n",
      "1  Riveramtza94\n",
      "1  Veropersefone\n",
      "1  scabel\n",
      "1  GILDA\n",
      "1  DaniiBonita\n",
      "1  Quyllur\n",
      "1  Mery Rea Torres\n",
      "1  soul_in_escape\n",
      "1  Rossi\n",
      "1  martinfranco\n",
      "1  Amorosa\n",
      "1  milu_mosha\n",
      "1  carlosherrera1978\n",
      "1  jef_pen\n",
      "1  OiramZ\n",
      "1  alfonsopocho\n",
      "1  La Doncella Tai\n",
      "1  Hugo Ignacio\n",
      "1  Leon_Milano\n",
      "1  Sanchez Marco\n",
      "1  yotem_josma\n",
      "1  aedu007\n",
      "1  betinho_moreliano\n",
      "1  david4884\n",
      "1  Juan Montenegro Viteri\n",
      "1  CaroFrancia\n",
      "1  mariela1989\n",
      "1  ktty\n",
      "1  Lunna\n",
      "1  papadou\n",
      "1  JAVIER ROLDAN\n",
      "1  javi garcia\n",
      "1  Yradiamos\n",
      "1  DulceCandy\n",
      "1  halcon nocturno\n",
      "1  sofi\n",
      "1  Sir_edu_poe\n",
      "1  claritabui\n",
      "1  ar2rito\n",
      "1  mc ar_: mis palabras...\n",
      "1  luthor\n",
      "1  Alex Vive\n",
      "1  ased\n",
      "1  farolito\n",
      "1  gea52\n",
      "1  monikita\n",
      "1  Pruden\n",
      "1  Rub√©n Omar\n",
      "1  Javiercito\n",
      "1  zadquiel\n",
      "1  Jhondayra\n",
      "1  strafer\n",
      "1  diego 3111\n",
      "1  Gibran\n",
      "1  PoetAlejo\n",
      "1  caloyero\n",
      "1  alejita\n",
      "1  baby4937\n",
      "1  Nathanael\n",
      "1  cote\n",
      "1  lunadeavellaneda\n",
      "1  Rosario Ayllon\n",
      "1  M.S.Carrera\n",
      "1  Luz Divina\n",
      "1  robiret\n",
      "1  Aron polanco\n",
      "1  juglar\n",
      "1  Kelii\n",
      "1  Paola Solis\n",
      "1  CRISTINA DE LEON MTZ\n",
      "1  Alguien del sur\n",
      "1  coco2500\n",
      "1  Jefribateri\n",
      "1  Raymond Cruz\n",
      "1  zHioPp\n",
      "1  aliscia\n",
      "1  NaraZam\n",
      "1  Coronel\n",
      "1  neuris\n",
      "1  lizzeth\n",
      "1  juana celia\n",
      "1  GaAbBo0\n",
      "1  marleni\n",
      "1  ediman\n",
      "1  manuc\n",
      "1  Sam Ballon\n",
      "1  ivan8910\n",
      "1  dp_shady\n",
      "1  02071949\n",
      "1  karen batres\n",
      "1  todosandcompany\n",
      "1  danescorpio\n",
      "1  luz argelia\n",
      "1  lilii\n",
      "1  adiikttha\n",
      "1  Esteban Molina\n",
      "1  xear29\n",
      "1  JUNIOR KENDALL\n",
      "1  Penny lane\n",
      "1  Txus_6\n",
      "1  raquel esmeralda ulloa seriol\n",
      "1  Michael M√©ndez\n",
      "1  juan ramon\n",
      "1  Edixon\n",
      "1  Julio Ferrero\n",
      "1  ramirofuentes\n",
      "1  ayelen12\n",
      "1  Irene_E\n",
      "1  Ema Valentina\n",
      "1  tx.dianita\n",
      "1  remembergrunge\n",
      "1  R. V.\n",
      "1  Poeta2007\n",
      "1  mayreli\n",
      "1  Bon Scott\n",
      "1  Blue Moon\n",
      "1  alexis...m25\n",
      "1  Azulito\n",
      "1  ---pau---\n",
      "1  JulioDublin\n",
      "1  foxof\n",
      "1  art.novo\n",
      "1  JHON0309\n",
      "1  MARGOTT\n",
      "1  xesca\n",
      "1  tatotuby\n",
      "1  TeNy_00\n",
      "1  Jackie\n",
      "1  daiane soares\n",
      "1  Owen\n",
      "1  lit\n",
      "1  xavi1708\n",
      "1  TAM\n",
      "1  luciox\n",
      "1  Melisa Luna\n",
      "1  aniluc\n",
      "1  jose valdez\n",
      "1  alicia casabuena\n",
      "1  hanssygirl\n",
      "1  herrera_raul\n",
      "1  Doris Gabriela\n",
      "1  Hanna Black\n",
      "1  kristal_godoy\n",
      "1  eloam\n",
      "1  Uriel art\n",
      "1  phoenix_ve\n",
      "1  christian bravo\n",
      "1  poeta_anonimo\n",
      "1  cristian solares\n",
      "1  Santiago\n",
      "1  itoz\n",
      "1  jhonsy002003\n",
      "1  vicho\n",
      "1  cristina21\n",
      "1  diexo_2009\n",
      "1  DAV\n",
      "1  Olivares Karen\n",
      "1  ovadic\n",
      "1  Pablo_Fabian\n",
      "1  rafaelito158\n",
      "1  Isaac Raniu\n",
      "1  AlejandroArguelles\n",
      "1  astro_mexicamaya\n",
      "1  Oscarmisael\n",
      "1  maria1990\n",
      "1  fabianx_x16\n",
      "1  jacquelinezlatar\n",
      "1  galy1296500\n",
      "1  AnnaMegar\n",
      "1  nehedonis\n",
      "1  rissa stefan\n",
      "1  sarax\n",
      "1  Mariana101\n",
      "1  Jesu Stonem\n",
      "1  yynericia\n",
      "1  santodo\n",
      "1  Agustin89\n",
      "1  Shalom Ferrin\n",
      "1  janneth\n",
      "1  janisa\n",
      "1  yoyito\n",
      "1  tanya precilla\n",
      "1  en ciscu sisquet\n",
      "1  Mercedes Aldana R\n",
      "1  DAVIDOCHOA\n",
      "1  ailuana\n",
      "1  jbconejo\n",
      "1  Johnnynas\n",
      "1  POETADOSISLAS\n",
      "1  labebe\n",
      "1  carmela\n",
      "1  zuleydy\n",
      "1  ricmavera\n",
      "1  bohemia\n",
      "1  grace vda. de de leon\n",
      "1  druida_hippie\n",
      "1  Franciscorivera\n",
      "1  bmpr1\n",
      "1  florsilvestre\n",
      "1  karo\n",
      "1  bettyZ.\n",
      "1  JAMBAL\n",
      "1  mapu\n",
      "1  juduve\n",
      "1  Omen\n",
      "1  DesVampirePoet\n",
      "1  araceli carrion\n",
      "1  ESCARENO\n",
      "1  Richhari\n",
      "1  yeye\n",
      "1  jose luis Hdez\n",
      "1  nagarita\n",
      "1  djpoeta\n",
      "1  monte_cristo\n",
      "1  M.A.R.I.O.\n",
      "1  diegoleoo\n",
      "1  juanpa\n",
      "1  Carlos Del Campo\n",
      "1  aepdiana\n",
      "1  Luis Alberto Gontade\n",
      "1  Mengana Utopika\n",
      "1  losdelsur721\n",
      "1  stoycobb\n",
      "1  VH\n",
      "1  Broken Heart\n",
      "1  luffyrc\n",
      "1  duroman\n",
      "1  rubi marlen\n",
      "1  Edilia Gabriel\n",
      "1  Mijael\n",
      "1  little love\n",
      "1  SIVONEY\n",
      "1  clarita pucci\n",
      "1  LiZzY LoVe\n",
      "1  josu√©\n",
      "1  VAMPIREZA\n",
      "1  negritoepunto\n",
      "1  Mauro Pereira Delfin\n",
      "1  Maylu\n",
      "1  erickwide\n",
      "1  Matias Sanchez\n",
      "1  PrinCesa Chocolina\n",
      "1  Henri de Lagarde - jneirasuarez\n",
      "1  Nadia la esperanza\n",
      "1  sai\n",
      "1  FRANK TORRES CHAMBI\n",
      "1  DanielaOrtiz\n",
      "1  yosoyyo\n",
      "1  maytejesus\n",
      "1  daniel.zer0\n",
      "1  Rosae\n",
      "1  Edwin Crespo Salamanca\n",
      "1  pankisilvestre\n",
      "1  AACCPP\n",
      "1  Jager462\n",
      "1  dely\n",
      "1  alejandra_guay\n",
      "1  Joseph Rodriguez\n",
      "1  Javi Zard\n",
      "1  laurix\n",
      "1  psique\n",
      "1  elec3co\n",
      "1  Ligia Lo. Unicornio\n",
      "1  WISH\n",
      "1  Libertad del Alma\n",
      "1  Luis Pascual Limi√±ana\n",
      "1  Darkness.cl\n",
      "1  kevingatito\n",
      "1  alanxxx\n",
      "1  edgar cardozo\n",
      "1  Elendrai\n",
      "1  vision of milo\n",
      "1  Kini...\n",
      "1  Fenix\n",
      "1  Maria Lopez\n",
      "1  wiro\n",
      "1  YESSIK\n",
      "1  selmi\n",
      "1  bigangel\n",
      "1  serenito55\n",
      "1  FELINA\n",
      "1  jesus guzman\n",
      "1  Elena Lisett Pereira\n",
      "1  tintaroja\n",
      "1  Rogina\n",
      "1  pau lluvia\n",
      "1  rossita4934\n",
      "1  andresmendieta\n",
      "1  diana melkor\n",
      "1  Leslie Erne\n",
      "1  pierruno\n",
      "1  Txema Anguera\n",
      "1  Elediz\n",
      "1  MrShadow23\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# make a list of the author from each row of poetry metadata, then\n",
    "# give that list to the Counter to count up\n",
    "author_counter = Counter([row['author'] for row in poetry_metadata])\n",
    "\n",
    "# list authors in decreasing order of how many poems they wrote.\n",
    "# To just list the top K authors, you can say .most_common(K),e.g.\n",
    "#    top_100_authors = author_counter.most_common(100)\n",
    "top_authors = author_counter.most_common()\n",
    "print(\"Total authors:\", len(top_authors))\n",
    "for author, count in top_authors:\n",
    "    print(count, author)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can scroll through this list and see we have some variety in how prolific our authors are: a small number have written a hundred or more poems, while a much larger number have only written one each. If we wanted to track how authors changed over time, we could limit ourselves just to poets who had contributed more than X poems. However, most projects I work on that take on something like this are more interested in not overrepresenting significant contributors.\n",
    "\n",
    "Let's look at a piece of code that samples no more than 10 poems from each author. This uses a special kind of Python dictionary, the `defaultdict`, that's a cousin of the Python `Counter`: it allows you to specify what the type is of values in the dictionary so that when you access a key that hasn't been used before, it provides a default value of that type. For instance, a `defaultdict(int)` would have a default value of 0, while a `defaultdict(list)` defaults to an empty list. (You can specify more complicated functions if you want for these, but let's leave it at that for now.\n",
    "\n",
    "We'll use our `defaultdict` to make a list of the entries as the value each author key by appending each entry to the list for that author. Then, we'll use Python's built-in `random` library to grab a sample for any that are too long."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of original collection: 14519\n",
      "Length of filtered collection: 7592\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "import random\n",
    "\n",
    "# Using the poetry_metadata variable from a few cells ago,\n",
    "# we'll make a list for each author\n",
    "metadata_by_author = defaultdict(list)\n",
    "for meta_dict in poetry_metadata:\n",
    "    metadata_by_author[meta_dict['author']].append(meta_dict)\n",
    "\n",
    "# Iterate through each of the keys (author names) in the list\n",
    "# and add up to 10 poems to our filtered list\n",
    "max_per_author = 10\n",
    "filtered_author_metadata = []\n",
    "for author in metadata_by_author:\n",
    "    if len(metadata_by_author[author]) > 10:\n",
    "        filtered_author_metadata += random.sample(metadata_by_author[author], max_per_author)\n",
    "    else:\n",
    "        filtered_author_metadata += metadata_by_author[author]\n",
    "        \n",
    "print(\"Length of original collection:\", len(poetry_metadata))\n",
    "print(\"Length of filtered collection:\", len(filtered_author_metadata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've now filtered down our collection by making some choices: namely, deciding we don't want to overrepresent any one author, and more specifically, that we want no more than ten poems from each author. This limits the size of our collection, but it may also make it easier for us to make certain arguments about what is (or isn't) in there; for instance, it would be harder to make the case that a particular trend was just the effect of one or a small group of members in the Poemas community.\n",
    "\n",
    "Once we have a filtered version of our collection, it's worth writing it out so that we don't have to regenerate it each time we run subsequent analyses. There are two reasons for this: first, because running this sort of processing can take a while on a larger collection, and second, because it helps us keep track of what version of the text we are using."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_tsv_from_dicts(filtered_author_metadata, \"poetry_metadata_22_6_27-author_limit_10.tsv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importantly, when we write out a processed version of a collection, we always want to keep track of the changes we made from the original collection to help with reporting and recreating our process later. Using an informative filename can help that (almost all my processed data files include the date I made them as well as some keywords for what changed), but there's no replacement for having an ongoing document that keeps track of your intermediate versions of \"cleaned\" text collections.\n",
    "\n",
    "**Warning**: Using something like a Jupyter notebook can make this problem feel like it's already solved, since you can add text around where you generated a particular file. However, **Jupyter notebooks only work as logs of your procedure if you don't go back and edit the script you used to generate the data!** If you think you might make a version 1 and then make some changes to your process for a version 2, 3, and so on, you should either make sure to record what you did in version 1 clearly in some place where that information won't get changed, or you should delete everything produced from the version 1 procedure so it can never accidentally be reused. Not doing this causes a *lot* of problems, especially if you have multiple people working on a project who might mistake an old file for the one to use.\n",
    "\n",
    "We've now seen a short introduction to working with TSV data. We could also have stored our data in comma-separated value (CSV) files by taking the code above and omitting the `delimiter` keyword:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This code should look familiar!\n",
    "import csv\n",
    "\n",
    "def read_csv_as_dicts(filename):\n",
    "    \"\"\"Load in a CSV, or comma-separated value file, using Python's \n",
    "    built-in library `csv` for parsing fixed delimiter files. Loads\n",
    "    in each row as a dictionary.\"\"\"\n",
    "    # open the file in read mode\n",
    "    with open(filename) as csv_file:\n",
    "        reader = csv.DictReader(csv_file)\n",
    "        row_dictionaries = [row for row in reader]\n",
    "    return row_dictionaries\n",
    "\n",
    "def write_csv_from_dicts(rows, filename):\n",
    "    \"\"\"Given a list of dictionaries with consistent keys, writes\n",
    "    out a comma-separated value file using Python's built-in library\n",
    "    `csv` to interpret the rows.\n",
    "    \"\"\"\n",
    "    # open a file in write mode\n",
    "    with open(filename, 'w') as csv_file:\n",
    "        # we grab the list of column names from the keys of\n",
    "        # one of the rows\n",
    "        columns = list(rows[0].keys())\n",
    "        writer = csv.DictWriter(csv_file, columns, delimiter='\\t')\n",
    "        writer.writeheader()\n",
    "        writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want, you can try these out and explore the differences in how this renders files. CSV files rely on quote characters and commas to separate out fields, which comes with a bit of danger for text processing, since commas show up quite often in text. CSV files will typically use a double quote `\"` as an *escape character* to define the boundaries of text so that commas inside a piece of text aren't read as the end of a column. This, in turn, produces interesting quirks for how to render quotes. If you use Python's `csv` library, it should take care of all of that for you, defaulting to the same behavior as what Microsoft Excel does, as specified by the default argument `dialect='excel'`. If you want to change this to another structure, I would recommend against trying to code it yourself, since it's easy to introduce errors, and instead check what dialect makes the most sense to use - you can even find Excel's official tab-separated value dialect!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['excel', 'excel-tab', 'unix']"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv.list_dialects()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've looked at storing and saving delimited files. Let's look at another format, the JSON file."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON, standards, and encodings\n",
    "\n",
    "\n",
    "JSON stands for **J**ava**S**cript **O**bject **N**otation. It's a syntax to describe structures of information based on how JavaScript makes objects, but because of its flexibility and clarity, it's also used in a variety of web applications and as a storage mechanism for some datasets.\n",
    "\n",
    "We can use Python's built-in `json` library to see what it would look like to write out the last ten of our unfiltered metadata from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27379\", \"title\": \":::::Sentidos:::::\", \"author\": \" Cock\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27382\", \"title\": \"TODO ES PERFECTO\", \"author\": \" chitto_cat\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27383\", \"title\": \"Esperandote\", \"author\": \" sagui\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27384\", \"title\": \"Al verte\", \"author\": \" Wilkis Santana\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27385\", \"title\": \"CUENTA REGRESIVA\", \"author\": \" Elediz\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27386\", \"title\": \"Fin...\", \"author\": \" robert marbre\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27388\", \"title\": \"Felizzz 2010!!\", \"author\": \" Lau_22\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27391\", \"title\": \"Una sombra mas\", \"author\": \" MrShadow23\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27395\", \"title\": \"A veces...\", \"author\": \" migreriana\", \"year\": 2009, \"month\": 12, \"page\": 8}, {\"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27399\", \"title\": \"Amor infinito\", \"author\": \" Latino\", \"year\": 2009, \"month\": 12, \"page\": 8}]\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "# use Python slicing and negative indexing to grab the\n",
    "# last 10 elements of the list\n",
    "last_ten_metadata = poetry_metadata[-10:]\n",
    "last_ten_json = json.dumps(last_ten_metadata)\n",
    "print(last_ten_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like a list of dictionaries, each of which seems to have different key-value pairs. We notice here that we haven't really done anything to indicate what's a number and what's a string, so everything is being written out as strings. We also might have a little trouble reading this the way it's printing right now - everything's running together in one long line. So let's see if we can make some fixes.\n",
    "\n",
    "First, let's turn our values for year, month, and page into actual integers! It's a basic for loop, but it's the sort of thing I end up doing all the time to help read in structured information by recasting the text of a number as an actual number. To get integers, I'll just use `int()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "for meta_dict in last_ten_metadata:\n",
    "    for key in [\"year\", \"month\", \"page\"]:\n",
    "        # replace the string with an integer from that string\n",
    "        meta_dict[key] = int(meta_dict[key])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Better - now let's try writing out the JSON format more legibly. One thing that would help is having some visible indentation to help us tell when something new is starting. The Python `json` library will let us do that with the keyword argument `indent` - every time a new dictionary or list starts, it will use an additional `indent` number of spaces to pad the start of the line. Here, with our list of ten items, it'll look like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27379\",\n",
      "    \"title\": \":::::Sentidos:::::\",\n",
      "    \"author\": \" Cock\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27382\",\n",
      "    \"title\": \"TODO ES PERFECTO\",\n",
      "    \"author\": \" chitto_cat\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27383\",\n",
      "    \"title\": \"Esperandote\",\n",
      "    \"author\": \" sagui\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27384\",\n",
      "    \"title\": \"Al verte\",\n",
      "    \"author\": \" Wilkis Santana\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27385\",\n",
      "    \"title\": \"CUENTA REGRESIVA\",\n",
      "    \"author\": \" Elediz\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27386\",\n",
      "    \"title\": \"Fin...\",\n",
      "    \"author\": \" robert marbre\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27388\",\n",
      "    \"title\": \"Felizzz 2010!!\",\n",
      "    \"author\": \" Lau_22\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27391\",\n",
      "    \"title\": \"Una sombra mas\",\n",
      "    \"author\": \" MrShadow23\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27395\",\n",
      "    \"title\": \"A veces...\",\n",
      "    \"author\": \" migreriana\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  },\n",
      "  {\n",
      "    \"url\": \"//www.poemas-del-alma.com/blog/mostrar-poema-27399\",\n",
      "    \"title\": \"Amor infinito\",\n",
      "    \"author\": \" Latino\",\n",
      "    \"year\": 2009,\n",
      "    \"month\": 12,\n",
      "    \"page\": 8\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Pretty print our new dictionary\n",
    "pretty_ten_json = json.dumps(last_ten_metadata, indent=2)\n",
    "print(pretty_ten_json)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Okay, that's much easier to read - we can see each entry separately, and we can see that while there are quotes around the URL, title, and author, the year, month, and page don't have quotes - we're supposed to read them as a piece of code would, which is as raw numbers, not as characters in a sequence.\n",
    "\n",
    "Importantly, these two versions of printing the text will have very different lengths and contents. We can also compare this to how much space the last ten lines would be in CSV form, which would just combine the fields in order. As mentioned before, we should usually let the `csv` library do the work of reading and writing these files, but for this example, I'll just turn everything back into a string myself and combine each line together with tabs using Python's string `join` method, which combines a list of strings into one using the calling string as a delimiter:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "//www.poemas-del-alma.com/blog/mostrar-poema-27379\t:::::Sentidos:::::\t Cock\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27382\tTODO ES PERFECTO\t chitto_cat\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27383\tEsperandote\t sagui\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27384\tAl verte\t Wilkis Santana\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27385\tCUENTA REGRESIVA\t Elediz\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27386\tFin...\t robert marbre\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27388\tFelizzz 2010!!\t Lau_22\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27391\tUna sombra mas\t MrShadow23\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27395\tA veces...\t migreriana\t2009\t12\t8\n",
      "//www.poemas-del-alma.com/blog/mostrar-poema-27399\tAmor infinito\t Latino\t2009\t12\t8\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tsv_keys = list(last_ten_metadata[0].keys())\n",
    "\n",
    "original_ten_tsv = \"\"\n",
    "for metadata in last_ten_metadata[-10:]:\n",
    "    # combine all fields with tabs\n",
    "    row_columns = [str(metadata[k]) for k in tsv_keys]\n",
    "    line = \"\\t\".join(row_columns)\n",
    "    # add the combined line and newline character\n",
    "    original_ten_tsv += line + \"\\n\"\n",
    "\n",
    "print(original_ten_tsv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's look at the relationship between how easy it is for us to read these strings versus how much space they take:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of characters in ten metadata fields\n",
      "Pretty JSON: 1802\n",
      "Raw JSON: 1500\n",
      "Raw TSV: 850\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of characters in ten metadata fields\")\n",
    "print(\"Pretty JSON:\", len(pretty_ten_json))\n",
    "print(\"Raw JSON:\", len(last_ten_json))\n",
    "print(\"Raw TSV:\", len(original_ten_tsv))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprised? Probably not - we spent extra space in our JSON representation to rewrite the names of our \"columns\" in every entry, and in the pretty printing, we also added bonus spaces. Of course, because of this format, JSON also has some flexibility we're not using: for instance, we can nest lists and objects inside other lists and objects, in the same way we could make a Python dictionary a value inside a Python dictionary. We can also choose to have some \"keys\" or attributes exist only some of the time; maybe if I had an author profile page for some authors but not others, I could add that attribute only where I need it in the JSON representation, but I would have to consistently have that column exist whether populated or not in the TSV representation. But it's worth talking about space because when we're representing data on computers in general, space adds up!\n",
    "\n",
    "To break this down a little more, let's review how strings store data. (I say review because I believe some of this is covered in the Intro to Python sequence for TAP.) A string is a list of characters, or symbols. Since computer memory is built to store information as binary numbers, a string is stored as a list of binary numbers, with one number for each character we see, which we call that symbol's *code point*. For instance, for pretty much any computer you'll use, the letter `A` has code point 65 if we're counting in base ten, and `a` has code point 97.\n",
    "\n",
    "A listing of these numbers is a *standard* - these numbers both come from the [ASCII standard](https://en.wikipedia.org/wiki/ASCII), or American Standard Code for Information Interchange, which dates back to the '60s. The ASCII standard is a product of its place and time: it goes from 0 to 127 and, fitting the expectations of popular characters for US English, it includes numbers, Latin letters without accents, punctuation, spacing, and a series of special symbols meant to match up to different typewriter operations. (After all, back in the 60's, typewriters were a standard way to handle input and output for computers.)\n",
    "\n",
    "The standard we interact with commonly online and on our phones is the [Unicode standard](https://en.wikipedia.org/wiki/Unicode). Unicode starts with the same 128 symbols as ASCII, but then extends well beyond that to include characters from other alphabets, diacritical marks, stylized symbols, and even emoji. It's also updated annually by the Unicode Consortium, a non-profit whose voting members comprise many well-known tech companies and research organizations. At the time of producing this tutorial, [Unicode 15.0 is about to be rolled out with over 149,000 characters](https://home.unicode.org/unicode-15-0-beta-review/).\n",
    "\n",
    "Of course, this gets at the way we map symbols to numbers, but to actually encode text - that is, to write it into our computer files and memory - we need a way to turn those numbers into a consistent sequence of ones and zeros. We call this a text encoding. Unicode actually has several different ways to do this.\n",
    "\n",
    "Let's give ourselves an example made-up username with some non-ASCII characters to see how this looks:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mar√≠a ‚òï\n"
     ]
    }
   ],
   "source": [
    "username = \"Mar\\u00EDa \\u2615\"\n",
    "print(username)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Python will get upset if we try to paste non-ASCII characters into a string, so to specify those characters as Unicode, we use the `\\u####` format to specify the code point of the symbol we want in *hexadeximal*. Hexadecimal is base 16, which has some more digits than the base-10 *decimal* counting system we're used to - it goes 0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, B, C, D, E, F, 10. The hexadecimal number 10 is equivalent to the decimal number sixteen. So, to write the decimal number forty-two, we'd use two sixteens and a ten, which we're write as 2A (2\\*16 + 10). If we wanted to write out sixteen squared in hexadecimal, we could just write 100, the same way 100 in our usual decimal counting system is ten squared. It's convenient for programming because each hexadecimal digit can be written using exactly four bits.\n",
    "\n",
    "We wrote this using two hexadecimal numbers, one for our i-acute and one for our coffee emoji. We can even use Python to convert the numbers out of hexadecimal (or \"hex\") if we'd like:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "√≠ has hex code point 00ED and dec code point 237\n",
      "‚òï has hex code point 2615 and dec code point 9749\n"
     ]
    }
   ],
   "source": [
    "print(\"\\u00ED\", \"has hex code point 00ED and dec code point\", int(\"00ED\", 16))\n",
    "print(\"\\u2615\", \"has hex code point 2615 and dec code point\", int(\"2615\", 16))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have unicode, let's think about exactly how much memory (not just how many characters) will get used by our different strings when we write them out using a particular encoding:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "utf-8 needs 6 bytes\n",
      "Hex code: 4d6172c3ad61\n",
      "\n",
      "utf-32 needs 24 bytes\n",
      "Hex code: fffe00004d0000006100000072000000ed00000061000000\n",
      "\n",
      "latin1 needs 5 bytes\n",
      "Hex code: 4d6172ed61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# get the text encoded using different encodings\n",
    "for encoding in ['utf-8', 'utf-32', 'latin1']:\n",
    "    byte_val = \"Mar\\u00EDa\".encode(encoding)\n",
    "    print(encoding, \"needs\", len(byte_val), \"bytes\")\n",
    "    print(\"Hex code:\", byte_val.hex())\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's going on? I've used three different encodings here for just the name Mar&#237;a: two associated with Unicode and one, `latin1`, that predates Unicode. (Heads up, `latin1`, or `ISO-8859-1`, used to be a common encoding for text based on a Latin alphabet with accents, so you may run into it now and again. If you get a bunch of As with accents instead of the text you expect from a document, try to read the file using `encoding=latin1` and see if that fixes it.)\n",
    "\n",
    "To break down what's going on here with each encoding:\n",
    "* `utf-8` uses a variable-length encoding, where one bit of each byte says whether it'll need another byte to write out the number or not. This means that for the four letters contained in ASCII, it only uses one byte each, but for the accented &#237;, it has to use two bytes, giving us 6 total bytes.\n",
    "* `utf-32` is fixed-length, but it uses four bytes (32 bits) for each symbol, plus an additional symbol at the front that tells it how it'll order the four bytes (since some programs read bytes front to back and others back to front). So, we get 5 * 4 + 4 bytes, or 24. If this was all emoji, this might have a lot more contents, but since it's mostly ASCII, we see a lot of 0s in the extra bytes.\n",
    "* `latin1` is explicitly designed to support some latin characters with accents without needing a second byte, so it is able to write the acute &#237; in one byte, using only five bytes. (However, if we needed to write the coffee emoji, it'd throw an error - try it!)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "[Proceed to next lesson: Text Curation 2/3 ->](./textcuration-2.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercises (Optional)\n",
    "\n",
    "`If possible, include practice exercises for users to do on their own. These may have clear solutions or be more open-ended.`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Solutions (Optional)\n",
    "`Offer some possible solutions for the practice exercises.`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References (Optional)\n",
    "No citations required but include this if you have cited academic sources. Use whatever format you like, just be consistent. Markdown footnotes are not well-supported in notebooks.[$^{1}$](#1) I suggest using an anchor link with plain html as shown.[$^{2}$](#2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. <a id=\"1\"></a> Here is an anchor link footnote.\n",
    "2. <a id=\"2\"></a> D'Ignazio, Catherine and Lauren F. Klein. [*Data Feminism*](https://mitpress.mit.edu/books/data-feminism). MIT Press, 2020."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
